{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentiment_dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPMCaQIqeh+QbvOW+xomsuQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/ml_tweepy_proj/blob/main/twitter_sentiment_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3GzmremJ_al"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "id": "bsBqSYANPTDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tweepy --upgrade"
      ],
      "metadata": {
        "id": "nMBVkxnNOFfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "mgRABScwS5F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAN3pZwEAAAAA46Nmy1JhTcXZshPRsK7mCR%2F3VrM%3Dwsq2MtBYeZMMxjfFUpje17BKz2euqmUfzpjq53mgsFQOueKutb\""
      ],
      "metadata": {
        "id": "46mmsl-oNpCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import csv\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "wtlPl7MpTR67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess text (username and link placeholders)\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        " \n",
        " \n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "hObN96z9cKjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tasks:\n",
        "# emoji, emotion, hate, irony, offensive, sentiment\n",
        "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
        "\n",
        "task='sentiment'\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "# download label mapping\n",
        "labels=[]\n",
        "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
        "with urllib.request.urlopen(mapping_link) as f:\n",
        "    html = f.read().decode('utf-8').split(\"\\n\")\n",
        "    csvreader = csv.reader(html, delimiter='\\t')\n",
        "labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "\n",
        "# PT\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)\n",
        "tokenizer.save_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "Vbmni7cecOY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy as tpy\n",
        "import tweepy as tweepy\n",
        "import pandas as pd\n",
        "\n",
        "client = tweepy.Client(\n",
        "    bearer_token=BEARER_TOKEN\n",
        ")"
      ],
      "metadata": {
        "id": "s8LQY43IL8Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_result=[]\n",
        "for tweet in tweepy.Paginator(client.search_recent_tweets, \"mercedes f1 -is:retweet\",\n",
        "                              max_results=100, user_fields=['id','username','location','verified','created_at'], \n",
        "                              tweet_fields=['id','author_id','created_at','geo','public_metrics','lang','source'],\n",
        "                              place_fields=['place_type', 'geo', 'country'], expansions=['geo.place_id', 'author_id']).flatten(limit=15000):\n",
        "  search_result.append(tweet)"
      ],
      "metadata": {
        "id": "T7sn5gb8QKIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(search_result)"
      ],
      "metadata": {
        "id": "DdCDWrvFileo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(search_result[0].text)\n",
        "print(search_result[0].created_at)\n",
        "print(search_result[0].geo)\n",
        "print(search_result[0].public_metrics)\n",
        "print(search_result[0].public_metrics['retweet_count'])\n",
        "print(search_result[0].public_metrics['reply_count'])\n",
        "print(search_result[0].public_metrics['like_count'])\n",
        "print(search_result[0].public_metrics['quote_count'])\n",
        "print(search_result[0].non_public_metrics)\n",
        "print(search_result[0].organic_metrics)\n",
        "print(search_result[0].promoted_metrics)\n",
        "print(search_result[0].id)\n",
        "print(search_result[0].author_id)\n",
        "print(search_result[0].source)\n",
        "print(search_result[0].lang)\n",
        "print(search_result[0].values)\n",
        "print(search_result[0].data)\n",
        "print(search_result[0].entities)\n",
        "print(search_result[0])\n",
        "print(dir(search_result[0]))\n",
        "\n"
      ],
      "metadata": {
        "id": "gq7Zi5Js70KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "faker = Faker()"
      ],
      "metadata": {
        "id": "5k5WP4p6Pfhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randrange"
      ],
      "metadata": {
        "id": "AhZRoz7EV-vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Faker.seed(0)\n",
        "fake_loc = faker.location_on_land()\n",
        "print(fake_loc[0])\n",
        "print(fake_loc[1])\n",
        "Faker.seed(0)"
      ],
      "metadata": {
        "id": "tGj3tMSiPZaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reliability_ind(lat_long):\n",
        "  try:\n",
        "    modu = 100 if abs(int(float(lat_long[1]))) > 100 else abs(int(float(lat_long[1])))\n",
        "    r_ind = (abs(int(float(lat_long[0]))) * abs(int(float(lat_long[1]))))\n",
        "    reliability_index = (randrange(0,r_ind) % modu) / 100\n",
        "  except:\n",
        "    reliability_index = 0\n",
        "  finally:\n",
        "    return reliability_index\n"
      ],
      "metadata": {
        "id": "wjwGVG-dZPzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_lists = []\n",
        "i=0\n",
        "for sr in search_result:\n",
        "  print(i)\n",
        "  i+=1\n",
        "  if (sr.lang == \"en\"):\n",
        "    text = sr.text\n",
        "    text = preprocess(text)\n",
        "    encoded_input = tokenizer(text, return_tensors='pt')\n",
        "    output = model(**encoded_input)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "\n",
        "    ranking = np.argsort(scores)\n",
        "    ranking = ranking[::-1]\n",
        "\n",
        "    fake_loc = faker.location_on_land()\n",
        "    rel_idx = reliability_ind(fake_loc)\n",
        "\n",
        "    list_of_lists.append([\n",
        "                          sr.id,\n",
        "                          sr.author_id,\n",
        "                          sr.text,\n",
        "                          fake_loc[0], \n",
        "                          fake_loc[1], \n",
        "                          sr.created_at, \n",
        "                          sr.source,\n",
        "                          sr.public_metrics['retweet_count'],\n",
        "                          sr.public_metrics['reply_count'],\n",
        "                          sr.public_metrics['like_count'],\n",
        "                          sr.public_metrics['quote_count'],\n",
        "                          rel_idx,\n",
        "                          str(labels[ranking[0]])])"
      ],
      "metadata": {
        "id": "cT5WuFbETeKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"id\",\"author_id\",\"tweet\",\"lat\",\"long\",\"created_at\",\"source\",\"retweet_count\",\"reply_count\",\"like_count\",\"quote_count\",\"reliability\",\"sentiment\"]\n",
        "df = pd.DataFrame(list_of_lists, columns=cols)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "TVCP34AZPJfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "9GXn3GqAk7bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "xE-EkQxhlB-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "J2Caex41ce6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))"
      ],
      "metadata": {
        "id": "XvLLcTsQVqnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace(r'\\r+|\\n+|\\t+',' ', regex=True)"
      ],
      "metadata": {
        "id": "-HbNId_qVxyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().any()"
      ],
      "metadata": {
        "id": "nuUHctuRV_t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "epoch_time = int(time.time())"
      ],
      "metadata": {
        "id": "-BqjZFqZQtXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"tweets_annotated.mercedes_f1.{}.csv\".format(epoch_time), header=cols, index=False, escapechar=\"\\\\\", encoding='utf-8')"
      ],
      "metadata": {
        "id": "2Sv7U7TeVG0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"tweets_annotated.mercedes_f1.{}.csv\".format(epoch_time))"
      ],
      "metadata": {
        "id": "XoQqKowjWZPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(5)"
      ],
      "metadata": {
        "id": "TRumQoyRWgyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['sentiment']. value_counts()"
      ],
      "metadata": {
        "id": "CeV_44HPWi9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.info()"
      ],
      "metadata": {
        "id": "N1iPYumYWnNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zmT_nZtLxzqU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}