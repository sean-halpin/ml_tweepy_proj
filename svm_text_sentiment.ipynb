{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm_text_sentiment.ipynb",
      "provenance": [],
      "mount_file_id": "1bpJik2FL13Sd2YXfH09APwYmr28ITcv-",
      "authorship_tag": "ABX9TyO2uVgMkAdTOMAmke2+ZL0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/ml_tweepy_proj/blob/main/svm_text_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "id": "zT5s9ms6s9ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install spellchecker\n",
        "!pip install pyspellchecker\n",
        "!pip install plot_keras_history"
      ],
      "metadata": {
        "id": "l_32RV-zeCXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "metadata": {
        "id": "FwEx4tlwsxq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def no_stopwords(text):\n",
        "  tokenwords = word_tokenize(text) \n",
        "  result = [w for w in tokenwords if not w in stop_words] \n",
        "  result = [] \n",
        "  for w in tokenwords: \n",
        "      if w not in stop_words: \n",
        "          result.append(w)\n",
        "  return \" \".join(result)"
      ],
      "metadata": {
        "id": "DsR1tpd2pQw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])"
      ],
      "metadata": {
        "id": "cza8vvcYrc_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output= string.punctuation\n",
        "print('list of punctuations:', output)"
      ],
      "metadata": {
        "id": "JNZIkIUslkTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_text_df(df):\n",
        "  df['tweet'] = df['tweet'].str.replace('http\\S+|www.\\S+|@.\\S+|&amp;.\\S+|<.*?>', '', case=False)\n",
        "  df['tweet'] = df['tweet'].str.lower()\n",
        "  df['tweet'] = df['tweet'].str.strip()\n",
        "  df['tweet'] = df['tweet'].str.translate(str.maketrans('', '', output))\n",
        "  df['lemmatized_tweet'] = df['tweet'].apply(lemmatize_text).apply(no_stopwords)\n",
        "  df = df.drop_duplicates('lemmatized_tweet', keep='last')\n",
        "  return df"
      ],
      "metadata": {
        "id": "aR2UvsKN-P1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_under_sample(X,y):\n",
        "  rus = RandomUnderSampler(random_state=0)\n",
        "  X_resampled, y_resampled = rus.fit_resample(X,y)\n",
        "  print(sorted(Counter(y_resampled).items()))\n",
        "  return X_resampled.flatten(), y_resampled.flatten()"
      ],
      "metadata": {
        "id": "biKHmIc4ZftK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_musk():\n",
        "  df = pd.read_csv(\"tweets_annotated.1650577206.elonmusk.csv\")\n",
        "  df = prepare_text_df(df)\n",
        "  X = df.lemmatized_tweet.values.reshape(-1,1)\n",
        "  y = df.sentiment.values.reshape(-1,1)\n",
        "  X_resampled, y_resampled = random_under_sample(X,y)\n",
        "  df_resampled = pd.DataFrame ({ 'lemmatized_tweet': X_resampled, 'sentiment': y_resampled})\n",
        "  return df_resampled"
      ],
      "metadata": {
        "id": "UbGJkBZWs0Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled = load_data_musk()"
      ],
      "metadata": {
        "id": "WIvaUyVoKG3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled.head()"
      ],
      "metadata": {
        "id": "RkY_CIBJdONZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "k0tVHkK0xMzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_resampled.lemmatized_tweet, df_resampled.sentiment, test_size=0.2, random_state=32)"
      ],
      "metadata": {
        "id": "yWYlxz8bx-Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classifier"
      ],
      "metadata": {
        "id": "hZnDCfyRvxnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer(max_features=100)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=3, tol=None)),\n",
        "])\n",
        "\n",
        "text_clf.fit(X_train, y_train)\n",
        "\n",
        "predicted = text_clf.predict(X_test)\n",
        "np.mean(predicted == y_test)"
      ],
      "metadata": {
        "id": "FDeKiuRww5T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "def clf_metrics(y_test, predicted):\n",
        "  print(metrics.classification_report(y_test, predicted))\n",
        "  c_matrix = metrics.confusion_matrix(y_test, predicted)\n",
        "  ax = sns.heatmap(c_matrix, annot=True,      \n",
        "                    xticklabels=['negative','neutral','positive'],                \n",
        "                    yticklabels=['negative','neutral','positive'],                \n",
        "                  cbar=True, cmap='Blues', fmt='g')\n",
        "  ax.set_xlabel(\"Prediction\")\n",
        "  ax.set_ylabel(\"Actual\")"
      ],
      "metadata": {
        "id": "jvRncbECb6m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test, predicted)"
      ],
      "metadata": {
        "id": "x-aQ8UYec9ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "\n",
        "def plot_learning_curve(\n",
        "    estimator,\n",
        "    title,\n",
        "    X,\n",
        "    y,\n",
        "    axes=None,\n",
        "    ylim=None,\n",
        "    cv=None,\n",
        "    n_jobs=None,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
        "):\n",
        "    if axes is None:\n",
        "        _, (ax) = plt.subplots(1, 1, figsize=(20, 5))\n",
        "\n",
        "    ax.set_title(title)\n",
        "    if ylim is not None:\n",
        "        ax.set_ylim(*ylim)\n",
        "    ax.set_xlabel(\"Training examples\")\n",
        "    ax.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
        "        estimator,\n",
        "        X,\n",
        "        y,\n",
        "        cv=cv,\n",
        "        n_jobs=n_jobs,\n",
        "        train_sizes=train_sizes,\n",
        "        return_times=True,\n",
        "    )\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    ax.grid()\n",
        "    ax.fill_between(\n",
        "        train_sizes,\n",
        "        train_scores_mean - train_scores_std,\n",
        "        train_scores_mean + train_scores_std,\n",
        "        alpha=0.1,\n",
        "        color=\"r\",\n",
        "    )\n",
        "    ax.fill_between(\n",
        "        train_sizes,\n",
        "        test_scores_mean - test_scores_std,\n",
        "        test_scores_mean + test_scores_std,\n",
        "        alpha=0.1,\n",
        "        color=\"g\",\n",
        "    )\n",
        "    ax.plot(\n",
        "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
        "    )\n",
        "    ax.plot(\n",
        "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
        "    )\n",
        "    ax.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "\n",
        "plot_learning_curve(\n",
        "    text_clf, \"LC \", X=X_test, y=y_test,ylim=(0.1, 1.01), cv=5, n_jobs=-1\n",
        ")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rzLGkp55v4uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Classification Performance against another topic"
      ],
      "metadata": {
        "id": "7InFQ38LAe10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_formula_one():\n",
        "  df_f1 = pd.read_csv(\"tweets_annotated.1650575029.formulaone.csv\")\n",
        "  df_f1 = prepare_text_df(df_f1)\n",
        "  X_f1 = df_f1.lemmatized_tweet.values.reshape(-1,1)\n",
        "  y_f1 = df_f1.sentiment.values.reshape(-1,1)\n",
        "  X_f1_resampled, y_f1_resampled = random_under_sample(X_f1,y_f1)\n",
        "  return pd.DataFrame ({ 'lemmatized_tweet': X_f1_resampled, 'sentiment': y_f1_resampled})"
      ],
      "metadata": {
        "id": "H3oIFOETK6bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_f1_resampled = load_data_formula_one()"
      ],
      "metadata": {
        "id": "fxDAbP7g9f3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_f1 = text_clf.predict(df_f1_resampled.lemmatized_tweet)"
      ],
      "metadata": {
        "id": "j-rQxfB7AQ8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(df_f1_resampled.sentiment, predicted_f1)"
      ],
      "metadata": {
        "id": "quFuNIqRArdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vader"
      ],
      "metadata": {
        "id": "qrMaqZMBvpqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "4IO2obn26CfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "def vader_sentiment(sentence):\n",
        "  vs = analyzer.polarity_scores(sentence)\n",
        "  comp = vs['compound']\n",
        "  if comp > 0.05:\n",
        "    return 'positive'\n",
        "  elif comp < -0.05:\n",
        "    return 'negative'\n",
        "  else:\n",
        "    return 'neutral'"
      ],
      "metadata": {
        "id": "rCMZRRrb5lNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vader_predicted = X_test.apply(vader_sentiment)"
      ],
      "metadata": {
        "id": "uiXINY-HefH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test, vader_predicted)"
      ],
      "metadata": {
        "id": "yv0Jd1scfCii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test[(y_test == \"neutral\") & (vader_predicted == \"positive\")])"
      ],
      "metadata": {
        "id": "sinyvvmZfley"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Neural Network Classifier"
      ],
      "metadata": {
        "id": "PbyiZMBA2JwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import gensim\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "VGraRTvu2M7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled = load_data_musk()"
      ],
      "metadata": {
        "id": "64a6tYr8JmtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labels_categorical(data):\n",
        "  labels = np.array(data)\n",
        "  y = []\n",
        "  for i in range(len(labels)):\n",
        "      if labels[i] == 'neutral':\n",
        "          y.append(0)\n",
        "      if labels[i] == 'negative':\n",
        "          y.append(1)\n",
        "      if labels[i] == 'positive':\n",
        "          y.append(2)\n",
        "  y = np.array(y)\n",
        "  labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "  del y\n",
        "  return labels"
      ],
      "metadata": {
        "id": "1SSI4v1k8J_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels_categorical(df_resampled.sentiment)"
      ],
      "metadata": {
        "id": "1gbZIrzF8s-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "\n",
        "max_words = 500\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df_resampled.lemmatized_tweet)\n",
        "sequences = tokenizer.texts_to_sequences(df_resampled.lemmatized_tweet)\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n",
        "print(tweets)"
      ],
      "metadata": {
        "id": "LTd9bp9gzSuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.3, random_state=32)"
      ],
      "metadata": {
        "id": "tq6zVGuA8xbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "cm3Mfpiq81CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding\n",
        "embedding_layer = Embedding(128, 16)\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(layers.Embedding(max_words, 12))\n",
        "model1.add(layers.LSTM(12,dropout=0.4, return_sequences=False))\n",
        "model1.add(layers.Dense(3,activation='softmax'))\n",
        "\n",
        "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4SY2V_ks3X7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "KOipYoR0APQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
        "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model1.fit(X_train, y_train, epochs=20,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
      ],
      "metadata": {
        "id": "KHjLziPmAyD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "best_model = keras.models.load_model(\"best_model1.hdf5\")"
      ],
      "metadata": {
        "id": "dnXIUOeAALPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ],
      "metadata": {
        "id": "G5r1a4CoAQoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "pw_1i4JmBE97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))"
      ],
      "metadata": {
        "id": "L1iDVUHX-usW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plot_keras_history import show_history, plot_history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "show_history(history)\n",
        "plot_history(history, path=\"standard.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "sY5wq9z9GEY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w-GTGB8E_sky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}