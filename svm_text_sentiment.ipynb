{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm_text_sentiment.ipynb",
      "provenance": [],
      "mount_file_id": "1bpJik2FL13Sd2YXfH09APwYmr28ITcv-",
      "authorship_tag": "ABX9TyNb333IKeXvHmWedS4aOHUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/ml_tweepy_proj/blob/main/svm_text_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install spellchecker\n",
        "!pip install pyspellchecker\n",
        "!pip install plot_keras_history"
      ],
      "metadata": {
        "id": "l_32RV-zeCXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "id": "zT5s9ms6s9ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem.wordnet import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "FwEx4tlwsxq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"tweets_annotated.1650577206.elonmusk.csv\")"
      ],
      "metadata": {
        "id": "UbGJkBZWs0Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def no_stopwords(text):\n",
        "  tokenwords = word_tokenize(text) \n",
        "  result = [w for w in tokenwords if not w in stop_words] \n",
        "  result = [] \n",
        "  for w in tokenwords: \n",
        "      if w not in stop_words: \n",
        "          result.append(w)\n",
        "  return \" \".join(result)"
      ],
      "metadata": {
        "id": "DsR1tpd2pQw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])"
      ],
      "metadata": {
        "id": "cza8vvcYrc_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output= string.punctuation\n",
        "print('list of punctuations:', output)"
      ],
      "metadata": {
        "id": "JNZIkIUslkTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'] = df['tweet'].str.replace('http\\S+|www.\\S+|@.\\S+|&amp;.\\S+|<.*?>', '', case=False)\n",
        "df['tweet'] = df['tweet'].str.lower()\n",
        "df['tweet'] = df['tweet'].str.strip()\n",
        "df['tweet'] = df['tweet'].str.translate(str.maketrans('', '', output))\n",
        "df['lemmatized_tweet'] = df['tweet'].apply(lemmatize_text).apply(no_stopwords)"
      ],
      "metadata": {
        "id": "9GbavaxZZG9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates('tweet', keep='last')"
      ],
      "metadata": {
        "id": "Z3DEAihohlOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.lemmatized_tweet.values.reshape(-1,1)\n",
        "y = df.sentiment.values.reshape(-1,1)"
      ],
      "metadata": {
        "id": "QyOGzEB9ZsKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "X_resampled, y_resampled = rus.fit_resample(X,y)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "metadata": {
        "id": "biKHmIc4ZftK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled = pd.DataFrame ({ 'lemmatized_tweet': X_resampled.flatten(), 'sentiment': y_resampled})"
      ],
      "metadata": {
        "id": "C-GzbM90bJaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled.head()"
      ],
      "metadata": {
        "id": "RkY_CIBJdONZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "k0tVHkK0xMzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_resampled.lemmatized_tweet, df_resampled.sentiment, test_size=0.3, random_state=32)"
      ],
      "metadata": {
        "id": "yWYlxz8bx-Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classifier"
      ],
      "metadata": {
        "id": "hZnDCfyRvxnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None)),\n",
        "])\n",
        "\n",
        "text_clf.fit(X_train, y_train)\n",
        "\n",
        "predicted = text_clf.predict(X_test)\n",
        "np.mean(predicted == y_test)"
      ],
      "metadata": {
        "id": "FDeKiuRww5T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "def clf_metrics(y_test, predicted):\n",
        "  print(metrics.classification_report(y_test, predicted))\n",
        "  c_matrix = metrics.confusion_matrix(y_test, predicted)\n",
        "  ax = sns.heatmap(c_matrix, annot=True,      \n",
        "                    xticklabels=['negative','neutral','positive'],                \n",
        "                    yticklabels=['negative','neutral','positive'],                \n",
        "                  cbar=True, cmap='Blues', fmt='g')\n",
        "  ax.set_xlabel(\"Prediction\")\n",
        "  ax.set_ylabel(\"Actual\")"
      ],
      "metadata": {
        "id": "jvRncbECb6m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test, predicted)"
      ],
      "metadata": {
        "id": "x-aQ8UYec9ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "\n",
        "def plot_learning_curve(\n",
        "    estimator,\n",
        "    title,\n",
        "    X,\n",
        "    y,\n",
        "    axes=None,\n",
        "    ylim=None,\n",
        "    cv=None,\n",
        "    n_jobs=None,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
        "):\n",
        "    if axes is None:\n",
        "        _, (ax) = plt.subplots(1, 1, figsize=(20, 5))\n",
        "\n",
        "    ax.set_title(title)\n",
        "    if ylim is not None:\n",
        "        ax.set_ylim(*ylim)\n",
        "    ax.set_xlabel(\"Training examples\")\n",
        "    ax.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
        "        estimator,\n",
        "        X,\n",
        "        y,\n",
        "        cv=cv,\n",
        "        n_jobs=n_jobs,\n",
        "        train_sizes=train_sizes,\n",
        "        return_times=True,\n",
        "    )\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    ax.grid()\n",
        "    ax.fill_between(\n",
        "        train_sizes,\n",
        "        train_scores_mean - train_scores_std,\n",
        "        train_scores_mean + train_scores_std,\n",
        "        alpha=0.1,\n",
        "        color=\"r\",\n",
        "    )\n",
        "    ax.fill_between(\n",
        "        train_sizes,\n",
        "        test_scores_mean - test_scores_std,\n",
        "        test_scores_mean + test_scores_std,\n",
        "        alpha=0.1,\n",
        "        color=\"g\",\n",
        "    )\n",
        "    ax.plot(\n",
        "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
        "    )\n",
        "    ax.plot(\n",
        "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
        "    )\n",
        "    ax.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "\n",
        "plot_learning_curve(\n",
        "    text_clf, \"LC \", X=X_test, y=y_test,ylim=(0.1, 1.01), cv=5, n_jobs=-1\n",
        ")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rzLGkp55v4uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vader"
      ],
      "metadata": {
        "id": "qrMaqZMBvpqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "4IO2obn26CfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "def vader_sentiment(sentence):\n",
        "  vs = analyzer.polarity_scores(sentence)\n",
        "  comp = vs['compound']\n",
        "  if comp > 0.05:\n",
        "    return 'positive'\n",
        "  elif comp < -0.05:\n",
        "    return 'negative'\n",
        "  else:\n",
        "    return 'neutral'"
      ],
      "metadata": {
        "id": "rCMZRRrb5lNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vader_predicted = X_test.apply(vader_sentiment)"
      ],
      "metadata": {
        "id": "uiXINY-HefH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test, vader_predicted)"
      ],
      "metadata": {
        "id": "yv0Jd1scfCii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('max_colwidth', -1)"
      ],
      "metadata": {
        "id": "ngp9I54_kS4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test[(y_test == \"neutral\") & (vader_predicted == \"positive\")])"
      ],
      "metadata": {
        "id": "sinyvvmZfley"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[(y_test == \"neutral\") & (vader_predicted == \"positive\")]"
      ],
      "metadata": {
        "id": "VgszAVv-h9u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Neural Network Classifier"
      ],
      "metadata": {
        "id": "PbyiZMBA2JwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import gensim\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "VGraRTvu2M7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labels_categorical(data):\n",
        "  labels = np.array(data)\n",
        "  y = []\n",
        "  for i in range(len(labels)):\n",
        "      if labels[i] == 'neutral':\n",
        "          y.append(0)\n",
        "      if labels[i] == 'negative':\n",
        "          y.append(1)\n",
        "      if labels[i] == 'positive':\n",
        "          y.append(2)\n",
        "  y = np.array(y)\n",
        "  labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "  del y\n",
        "  return labels"
      ],
      "metadata": {
        "id": "1SSI4v1k8J_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels_categorical(df_resampled.sentiment)"
      ],
      "metadata": {
        "id": "1gbZIrzF8s-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "\n",
        "max_words = 2500\n",
        "max_len = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df_resampled.lemmatized_tweet)\n",
        "sequences = tokenizer.texts_to_sequences(df_resampled.lemmatized_tweet)\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n",
        "print(tweets)"
      ],
      "metadata": {
        "id": "LTd9bp9gzSuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.3, random_state=32)"
      ],
      "metadata": {
        "id": "tq6zVGuA8xbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "cm3Mfpiq81CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding\n",
        "embedding_layer = Embedding(1000, 32)\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(layers.Embedding(max_words, 10))\n",
        "model1.add(layers.LSTM(90,dropout=0.5, return_sequences=True))\n",
        "model1.add(layers.LSTM(90,dropout=0.5, return_sequences=True))\n",
        "model1.add(layers.LSTM(30,dropout=0.5, return_sequences=False))\n",
        "model1.add(layers.Dense(3,activation='softmax'))\n",
        "\n",
        "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4SY2V_ks3X7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "KOipYoR0APQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
        "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model1.fit(X_train, y_train, epochs=200,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHjLziPmAyD_",
        "outputId": "9535c4c5-7daf-40dc-e84e-9886444958bb"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82/83 [============================>.] - ETA: 0s - loss: 0.9188 - accuracy: 0.5316\n",
            "Epoch 4: val_accuracy improved from 0.47298 to 0.54827, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.9192 - accuracy: 0.5317 - val_loss: 0.9732 - val_accuracy: 0.5483\n",
            "Epoch 5/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.8803 - accuracy: 0.5789\n",
            "Epoch 5: val_accuracy did not improve from 0.54827\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.8793 - accuracy: 0.5792 - val_loss: 0.9822 - val_accuracy: 0.4969\n",
            "Epoch 6/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.8386 - accuracy: 0.6076\n",
            "Epoch 6: val_accuracy did not improve from 0.54827\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.8421 - accuracy: 0.6058 - val_loss: 0.9441 - val_accuracy: 0.5412\n",
            "Epoch 7/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.8085 - accuracy: 0.6277\n",
            "Epoch 7: val_accuracy improved from 0.54827 to 0.55802, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.8068 - accuracy: 0.6293 - val_loss: 0.9430 - val_accuracy: 0.5580\n",
            "Epoch 8/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7943 - accuracy: 0.6441\n",
            "Epoch 8: val_accuracy did not improve from 0.55802\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.7943 - accuracy: 0.6441 - val_loss: 0.9136 - val_accuracy: 0.5536\n",
            "Epoch 9/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.7785 - accuracy: 0.6470\n",
            "Epoch 9: val_accuracy improved from 0.55802 to 0.55979, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.7783 - accuracy: 0.6476 - val_loss: 0.9189 - val_accuracy: 0.5598\n",
            "Epoch 10/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.7491 - accuracy: 0.6659\n",
            "Epoch 10: val_accuracy did not improve from 0.55979\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.7489 - accuracy: 0.6662 - val_loss: 0.9340 - val_accuracy: 0.5509\n",
            "Epoch 11/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7378 - accuracy: 0.6802\n",
            "Epoch 11: val_accuracy improved from 0.55979 to 0.57396, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.7378 - accuracy: 0.6802 - val_loss: 0.9656 - val_accuracy: 0.5740\n",
            "Epoch 12/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.7354 - accuracy: 0.6782\n",
            "Epoch 12: val_accuracy did not improve from 0.57396\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.7347 - accuracy: 0.6783 - val_loss: 0.9281 - val_accuracy: 0.5695\n",
            "Epoch 13/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7219 - accuracy: 0.6776\n",
            "Epoch 13: val_accuracy improved from 0.57396 to 0.58193, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.7219 - accuracy: 0.6776 - val_loss: 0.9227 - val_accuracy: 0.5819\n",
            "Epoch 14/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.7187 - accuracy: 0.6837\n",
            "Epoch 14: val_accuracy did not improve from 0.58193\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.7188 - accuracy: 0.6840 - val_loss: 0.9339 - val_accuracy: 0.5722\n",
            "Epoch 15/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.7032 - accuracy: 0.6998\n",
            "Epoch 15: val_accuracy improved from 0.58193 to 0.59433, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.7024 - accuracy: 0.7003 - val_loss: 0.9283 - val_accuracy: 0.5943\n",
            "Epoch 16/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7055 - accuracy: 0.6977\n",
            "Epoch 16: val_accuracy did not improve from 0.59433\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.7055 - accuracy: 0.6977 - val_loss: 0.9237 - val_accuracy: 0.5837\n",
            "Epoch 17/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.7083 - accuracy: 0.6829\n",
            "Epoch 17: val_accuracy did not improve from 0.59433\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.7082 - accuracy: 0.6829 - val_loss: 0.9066 - val_accuracy: 0.5934\n",
            "Epoch 18/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.7000\n",
            "Epoch 18: val_accuracy did not improve from 0.59433\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6900 - accuracy: 0.7000 - val_loss: 0.9130 - val_accuracy: 0.5934\n",
            "Epoch 19/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.6775 - accuracy: 0.7001\n",
            "Epoch 19: val_accuracy did not improve from 0.59433\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6786 - accuracy: 0.6996 - val_loss: 0.9103 - val_accuracy: 0.5899\n",
            "Epoch 20/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6783 - accuracy: 0.7068\n",
            "Epoch 20: val_accuracy improved from 0.59433 to 0.59699, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6778 - accuracy: 0.7076 - val_loss: 0.9081 - val_accuracy: 0.5970\n",
            "Epoch 21/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.7096\n",
            "Epoch 21: val_accuracy did not improve from 0.59699\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6776 - accuracy: 0.7095 - val_loss: 0.9098 - val_accuracy: 0.5934\n",
            "Epoch 22/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.6744 - accuracy: 0.7161\n",
            "Epoch 22: val_accuracy improved from 0.59699 to 0.60585, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6748 - accuracy: 0.7163 - val_loss: 0.8936 - val_accuracy: 0.6058\n",
            "Epoch 23/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6675 - accuracy: 0.7034\n",
            "Epoch 23: val_accuracy did not improve from 0.60585\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6675 - accuracy: 0.7034 - val_loss: 0.9134 - val_accuracy: 0.5943\n",
            "Epoch 24/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6677 - accuracy: 0.7145\n",
            "Epoch 24: val_accuracy did not improve from 0.60585\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6693 - accuracy: 0.7121 - val_loss: 0.9279 - val_accuracy: 0.6005\n",
            "Epoch 25/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6547 - accuracy: 0.7172\n",
            "Epoch 25: val_accuracy did not improve from 0.60585\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6595 - accuracy: 0.7163 - val_loss: 0.9170 - val_accuracy: 0.6032\n",
            "Epoch 26/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6640 - accuracy: 0.7174\n",
            "Epoch 26: val_accuracy did not improve from 0.60585\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6640 - accuracy: 0.7174 - val_loss: 0.9195 - val_accuracy: 0.6041\n",
            "Epoch 27/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6688 - accuracy: 0.7102\n",
            "Epoch 27: val_accuracy did not improve from 0.60585\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6658 - accuracy: 0.7110 - val_loss: 0.9275 - val_accuracy: 0.5961\n",
            "Epoch 28/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6562 - accuracy: 0.7288\n",
            "Epoch 28: val_accuracy did not improve from 0.60585\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6554 - accuracy: 0.7288 - val_loss: 0.9234 - val_accuracy: 0.6005\n",
            "Epoch 29/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6599 - accuracy: 0.7148\n",
            "Epoch 29: val_accuracy did not improve from 0.60585\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6599 - accuracy: 0.7148 - val_loss: 0.9754 - val_accuracy: 0.5943\n",
            "Epoch 30/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6453 - accuracy: 0.7258\n",
            "Epoch 30: val_accuracy did not improve from 0.60585\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.6453 - accuracy: 0.7258 - val_loss: 0.9719 - val_accuracy: 0.5952\n",
            "Epoch 31/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6498 - accuracy: 0.7249\n",
            "Epoch 31: val_accuracy did not improve from 0.60585\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6508 - accuracy: 0.7243 - val_loss: 0.9358 - val_accuracy: 0.5943\n",
            "Epoch 32/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6355 - accuracy: 0.7312\n",
            "Epoch 32: val_accuracy improved from 0.60585 to 0.60762, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 2s 23ms/step - loss: 0.6345 - accuracy: 0.7303 - val_loss: 0.9491 - val_accuracy: 0.6076\n",
            "Epoch 33/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6507 - accuracy: 0.7195\n",
            "Epoch 33: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6478 - accuracy: 0.7216 - val_loss: 0.9531 - val_accuracy: 0.5979\n",
            "Epoch 34/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6377 - accuracy: 0.7307\n",
            "Epoch 34: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6381 - accuracy: 0.7315 - val_loss: 0.9411 - val_accuracy: 0.5996\n",
            "Epoch 35/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6420 - accuracy: 0.7334\n",
            "Epoch 35: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6410 - accuracy: 0.7330 - val_loss: 0.9877 - val_accuracy: 0.5979\n",
            "Epoch 36/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6407 - accuracy: 0.7238\n",
            "Epoch 36: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6363 - accuracy: 0.7273 - val_loss: 1.0209 - val_accuracy: 0.5988\n",
            "Epoch 37/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6354 - accuracy: 0.7375\n",
            "Epoch 37: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6364 - accuracy: 0.7379 - val_loss: 0.9779 - val_accuracy: 0.6005\n",
            "Epoch 38/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6397 - accuracy: 0.7235\n",
            "Epoch 38: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6397 - accuracy: 0.7235 - val_loss: 0.9525 - val_accuracy: 0.6005\n",
            "Epoch 39/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6403 - accuracy: 0.7326\n",
            "Epoch 39: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6395 - accuracy: 0.7322 - val_loss: 0.9299 - val_accuracy: 0.6050\n",
            "Epoch 40/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.6290 - accuracy: 0.7351\n",
            "Epoch 40: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6288 - accuracy: 0.7357 - val_loss: 0.9731 - val_accuracy: 0.5996\n",
            "Epoch 41/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6338 - accuracy: 0.7350\n",
            "Epoch 41: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6323 - accuracy: 0.7353 - val_loss: 0.9776 - val_accuracy: 0.5988\n",
            "Epoch 42/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6298 - accuracy: 0.7342\n",
            "Epoch 42: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6320 - accuracy: 0.7338 - val_loss: 0.9699 - val_accuracy: 0.5934\n",
            "Epoch 43/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6277 - accuracy: 0.7388\n",
            "Epoch 43: val_accuracy did not improve from 0.60762\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6266 - accuracy: 0.7395 - val_loss: 0.9788 - val_accuracy: 0.6014\n",
            "Epoch 44/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.6218 - accuracy: 0.7329\n",
            "Epoch 44: val_accuracy improved from 0.60762 to 0.61116, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 2s 28ms/step - loss: 0.6228 - accuracy: 0.7326 - val_loss: 0.9662 - val_accuracy: 0.6112\n",
            "Epoch 45/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6253 - accuracy: 0.7303\n",
            "Epoch 45: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6263 - accuracy: 0.7300 - val_loss: 0.9899 - val_accuracy: 0.6076\n",
            "Epoch 46/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6191 - accuracy: 0.7384\n",
            "Epoch 46: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6181 - accuracy: 0.7387 - val_loss: 1.0058 - val_accuracy: 0.6005\n",
            "Epoch 47/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.7357\n",
            "Epoch 47: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6197 - accuracy: 0.7357 - val_loss: 0.9807 - val_accuracy: 0.5979\n",
            "Epoch 48/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6335 - accuracy: 0.7338\n",
            "Epoch 48: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6368 - accuracy: 0.7319 - val_loss: 0.9442 - val_accuracy: 0.6014\n",
            "Epoch 49/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.6268 - accuracy: 0.7382\n",
            "Epoch 49: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6266 - accuracy: 0.7383 - val_loss: 0.9632 - val_accuracy: 0.6050\n",
            "Epoch 50/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.7425\n",
            "Epoch 50: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6251 - accuracy: 0.7425 - val_loss: 0.9561 - val_accuracy: 0.6050\n",
            "Epoch 51/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6216 - accuracy: 0.7336\n",
            "Epoch 51: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.6240 - accuracy: 0.7319 - val_loss: 0.9799 - val_accuracy: 0.6005\n",
            "Epoch 52/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6186 - accuracy: 0.7346\n",
            "Epoch 52: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6189 - accuracy: 0.7345 - val_loss: 0.9553 - val_accuracy: 0.6023\n",
            "Epoch 53/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6284 - accuracy: 0.7330\n",
            "Epoch 53: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6284 - accuracy: 0.7330 - val_loss: 0.9508 - val_accuracy: 0.6005\n",
            "Epoch 54/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6166 - accuracy: 0.7350\n",
            "Epoch 54: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6158 - accuracy: 0.7353 - val_loss: 0.9786 - val_accuracy: 0.6067\n",
            "Epoch 55/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6068 - accuracy: 0.7345\n",
            "Epoch 55: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6068 - accuracy: 0.7345 - val_loss: 0.9733 - val_accuracy: 0.5970\n",
            "Epoch 56/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6103 - accuracy: 0.7461\n",
            "Epoch 56: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6108 - accuracy: 0.7467 - val_loss: 0.9473 - val_accuracy: 0.6023\n",
            "Epoch 57/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6107 - accuracy: 0.7461\n",
            "Epoch 57: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6137 - accuracy: 0.7455 - val_loss: 0.9724 - val_accuracy: 0.6067\n",
            "Epoch 58/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6097 - accuracy: 0.7357\n",
            "Epoch 58: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6086 - accuracy: 0.7357 - val_loss: 0.9903 - val_accuracy: 0.6067\n",
            "Epoch 59/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6224 - accuracy: 0.7406\n",
            "Epoch 59: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6192 - accuracy: 0.7414 - val_loss: 1.0000 - val_accuracy: 0.6103\n",
            "Epoch 60/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6145 - accuracy: 0.7457\n",
            "Epoch 60: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6151 - accuracy: 0.7444 - val_loss: 0.9506 - val_accuracy: 0.6032\n",
            "Epoch 61/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6111 - accuracy: 0.7434\n",
            "Epoch 61: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.6084 - accuracy: 0.7452 - val_loss: 0.9810 - val_accuracy: 0.5961\n",
            "Epoch 62/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6024 - accuracy: 0.7461\n",
            "Epoch 62: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6025 - accuracy: 0.7455 - val_loss: 0.9930 - val_accuracy: 0.6023\n",
            "Epoch 63/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6125 - accuracy: 0.7402\n",
            "Epoch 63: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6150 - accuracy: 0.7387 - val_loss: 0.9933 - val_accuracy: 0.5872\n",
            "Epoch 64/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6019 - accuracy: 0.7492\n",
            "Epoch 64: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6025 - accuracy: 0.7493 - val_loss: 1.0056 - val_accuracy: 0.6005\n",
            "Epoch 65/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5919 - accuracy: 0.7426\n",
            "Epoch 65: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5929 - accuracy: 0.7436 - val_loss: 1.0131 - val_accuracy: 0.5908\n",
            "Epoch 66/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5971 - accuracy: 0.7473\n",
            "Epoch 66: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6013 - accuracy: 0.7448 - val_loss: 1.0210 - val_accuracy: 0.5952\n",
            "Epoch 67/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6170 - accuracy: 0.7373\n",
            "Epoch 67: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6182 - accuracy: 0.7360 - val_loss: 0.9958 - val_accuracy: 0.6058\n",
            "Epoch 68/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5999 - accuracy: 0.7367\n",
            "Epoch 68: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6019 - accuracy: 0.7360 - val_loss: 0.9701 - val_accuracy: 0.5970\n",
            "Epoch 69/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6094 - accuracy: 0.7543\n",
            "Epoch 69: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6076 - accuracy: 0.7547 - val_loss: 0.9778 - val_accuracy: 0.5979\n",
            "Epoch 70/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5927 - accuracy: 0.7593\n",
            "Epoch 70: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5931 - accuracy: 0.7600 - val_loss: 0.9831 - val_accuracy: 0.6050\n",
            "Epoch 71/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.6043 - accuracy: 0.7488\n",
            "Epoch 71: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6079 - accuracy: 0.7474 - val_loss: 0.9879 - val_accuracy: 0.5970\n",
            "Epoch 72/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.6120 - accuracy: 0.7465\n",
            "Epoch 72: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.6137 - accuracy: 0.7448 - val_loss: 0.9806 - val_accuracy: 0.5979\n",
            "Epoch 73/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5881 - accuracy: 0.7631\n",
            "Epoch 73: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5869 - accuracy: 0.7626 - val_loss: 0.9952 - val_accuracy: 0.5952\n",
            "Epoch 74/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5899 - accuracy: 0.7531\n",
            "Epoch 74: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5896 - accuracy: 0.7528 - val_loss: 0.9848 - val_accuracy: 0.6050\n",
            "Epoch 75/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5859 - accuracy: 0.7554\n",
            "Epoch 75: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5875 - accuracy: 0.7550 - val_loss: 1.0068 - val_accuracy: 0.5917\n",
            "Epoch 76/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5890 - accuracy: 0.7542\n",
            "Epoch 76: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5889 - accuracy: 0.7539 - val_loss: 1.0142 - val_accuracy: 0.5979\n",
            "Epoch 77/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.7440\n",
            "Epoch 77: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5969 - accuracy: 0.7440 - val_loss: 0.9831 - val_accuracy: 0.6058\n",
            "Epoch 78/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5981 - accuracy: 0.7457\n",
            "Epoch 78: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5927 - accuracy: 0.7490 - val_loss: 1.0494 - val_accuracy: 0.6050\n",
            "Epoch 79/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5918 - accuracy: 0.7508\n",
            "Epoch 79: val_accuracy did not improve from 0.61116\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5940 - accuracy: 0.7497 - val_loss: 0.9828 - val_accuracy: 0.6076\n",
            "Epoch 80/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5901 - accuracy: 0.7550\n",
            "Epoch 80: val_accuracy improved from 0.61116 to 0.61205, saving model to best_model1.hdf5\n",
            "83/83 [==============================] - 2s 27ms/step - loss: 0.5913 - accuracy: 0.7531 - val_loss: 1.0046 - val_accuracy: 0.6120\n",
            "Epoch 81/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5994 - accuracy: 0.7461\n",
            "Epoch 81: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5989 - accuracy: 0.7455 - val_loss: 1.0164 - val_accuracy: 0.5961\n",
            "Epoch 82/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.7596\n",
            "Epoch 82: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5783 - accuracy: 0.7585 - val_loss: 1.0165 - val_accuracy: 0.5881\n",
            "Epoch 83/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5862 - accuracy: 0.7595\n",
            "Epoch 83: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5852 - accuracy: 0.7603 - val_loss: 1.0236 - val_accuracy: 0.6032\n",
            "Epoch 84/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5760 - accuracy: 0.7594\n",
            "Epoch 84: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5792 - accuracy: 0.7585 - val_loss: 1.0105 - val_accuracy: 0.5934\n",
            "Epoch 85/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5851 - accuracy: 0.7539\n",
            "Epoch 85: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5832 - accuracy: 0.7535 - val_loss: 1.0036 - val_accuracy: 0.5952\n",
            "Epoch 86/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5896 - accuracy: 0.7458\n",
            "Epoch 86: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5940 - accuracy: 0.7436 - val_loss: 0.9806 - val_accuracy: 0.5917\n",
            "Epoch 87/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5882 - accuracy: 0.7515\n",
            "Epoch 87: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5888 - accuracy: 0.7512 - val_loss: 1.0389 - val_accuracy: 0.5988\n",
            "Epoch 88/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5702 - accuracy: 0.7593\n",
            "Epoch 88: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5677 - accuracy: 0.7615 - val_loss: 1.0423 - val_accuracy: 0.5881\n",
            "Epoch 89/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5677 - accuracy: 0.7633\n",
            "Epoch 89: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5684 - accuracy: 0.7622 - val_loss: 1.0312 - val_accuracy: 0.5926\n",
            "Epoch 90/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5737 - accuracy: 0.7594\n",
            "Epoch 90: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5767 - accuracy: 0.7577 - val_loss: 1.0174 - val_accuracy: 0.5961\n",
            "Epoch 91/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5667 - accuracy: 0.7674\n",
            "Epoch 91: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5655 - accuracy: 0.7679 - val_loss: 1.0495 - val_accuracy: 0.5810\n",
            "Epoch 92/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5711 - accuracy: 0.7559\n",
            "Epoch 92: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5695 - accuracy: 0.7562 - val_loss: 1.0234 - val_accuracy: 0.5970\n",
            "Epoch 93/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5845 - accuracy: 0.7563\n",
            "Epoch 93: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5838 - accuracy: 0.7569 - val_loss: 0.9985 - val_accuracy: 0.5943\n",
            "Epoch 94/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5698 - accuracy: 0.7570\n",
            "Epoch 94: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5715 - accuracy: 0.7569 - val_loss: 1.0332 - val_accuracy: 0.5899\n",
            "Epoch 95/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.7647\n",
            "Epoch 95: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5593 - accuracy: 0.7638 - val_loss: 1.0318 - val_accuracy: 0.5952\n",
            "Epoch 96/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5825 - accuracy: 0.7508\n",
            "Epoch 96: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5833 - accuracy: 0.7497 - val_loss: 1.0272 - val_accuracy: 0.5952\n",
            "Epoch 97/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5656 - accuracy: 0.7599\n",
            "Epoch 97: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5662 - accuracy: 0.7596 - val_loss: 1.0660 - val_accuracy: 0.6023\n",
            "Epoch 98/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5689 - accuracy: 0.7623\n",
            "Epoch 98: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5674 - accuracy: 0.7634 - val_loss: 1.0419 - val_accuracy: 0.5943\n",
            "Epoch 99/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5641 - accuracy: 0.7652\n",
            "Epoch 99: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5631 - accuracy: 0.7664 - val_loss: 1.0588 - val_accuracy: 0.5881\n",
            "Epoch 100/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5706 - accuracy: 0.7565\n",
            "Epoch 100: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5705 - accuracy: 0.7562 - val_loss: 1.0529 - val_accuracy: 0.5917\n",
            "Epoch 101/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5593 - accuracy: 0.7720\n",
            "Epoch 101: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5587 - accuracy: 0.7717 - val_loss: 1.0578 - val_accuracy: 0.6014\n",
            "Epoch 102/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5589 - accuracy: 0.7643\n",
            "Epoch 102: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5615 - accuracy: 0.7634 - val_loss: 1.0393 - val_accuracy: 0.5881\n",
            "Epoch 103/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7626\n",
            "Epoch 103: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5667 - accuracy: 0.7626 - val_loss: 1.0167 - val_accuracy: 0.5917\n",
            "Epoch 104/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5653 - accuracy: 0.7658\n",
            "Epoch 104: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5634 - accuracy: 0.7676 - val_loss: 1.0220 - val_accuracy: 0.5970\n",
            "Epoch 105/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.7677\n",
            "Epoch 105: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5595 - accuracy: 0.7664 - val_loss: 1.0352 - val_accuracy: 0.5890\n",
            "Epoch 106/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5685 - accuracy: 0.7608\n",
            "Epoch 106: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5697 - accuracy: 0.7611 - val_loss: 1.0231 - val_accuracy: 0.5846\n",
            "Epoch 107/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5466 - accuracy: 0.7751\n",
            "Epoch 107: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5453 - accuracy: 0.7759 - val_loss: 1.0750 - val_accuracy: 0.5837\n",
            "Epoch 108/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5475 - accuracy: 0.7789\n",
            "Epoch 108: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5447 - accuracy: 0.7793 - val_loss: 1.0967 - val_accuracy: 0.5899\n",
            "Epoch 109/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5485 - accuracy: 0.7778\n",
            "Epoch 109: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5472 - accuracy: 0.7778 - val_loss: 1.0816 - val_accuracy: 0.5926\n",
            "Epoch 110/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5451 - accuracy: 0.7652\n",
            "Epoch 110: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.7653 - val_loss: 1.0723 - val_accuracy: 0.5934\n",
            "Epoch 111/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5513 - accuracy: 0.7685\n",
            "Epoch 111: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5511 - accuracy: 0.7679 - val_loss: 1.0611 - val_accuracy: 0.5881\n",
            "Epoch 112/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.7720\n",
            "Epoch 112: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5383 - accuracy: 0.7744 - val_loss: 1.1086 - val_accuracy: 0.5943\n",
            "Epoch 113/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5636 - accuracy: 0.7596\n",
            "Epoch 113: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5633 - accuracy: 0.7588 - val_loss: 1.0325 - val_accuracy: 0.6032\n",
            "Epoch 114/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5467 - accuracy: 0.7789\n",
            "Epoch 114: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5510 - accuracy: 0.7755 - val_loss: 1.0664 - val_accuracy: 0.5996\n",
            "Epoch 115/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5621 - accuracy: 0.7662\n",
            "Epoch 115: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5610 - accuracy: 0.7660 - val_loss: 1.0571 - val_accuracy: 0.5979\n",
            "Epoch 116/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5346 - accuracy: 0.7758\n",
            "Epoch 116: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5377 - accuracy: 0.7748 - val_loss: 1.0393 - val_accuracy: 0.5961\n",
            "Epoch 117/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5300 - accuracy: 0.7843\n",
            "Epoch 117: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5356 - accuracy: 0.7820 - val_loss: 1.0679 - val_accuracy: 0.5988\n",
            "Epoch 118/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5628 - accuracy: 0.7566\n",
            "Epoch 118: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5642 - accuracy: 0.7554 - val_loss: 1.0804 - val_accuracy: 0.5899\n",
            "Epoch 119/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.7758\n",
            "Epoch 119: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5358 - accuracy: 0.7744 - val_loss: 1.0915 - val_accuracy: 0.5934\n",
            "Epoch 120/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5434 - accuracy: 0.7716\n",
            "Epoch 120: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5419 - accuracy: 0.7740 - val_loss: 1.0967 - val_accuracy: 0.5890\n",
            "Epoch 121/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.7809\n",
            "Epoch 121: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5400 - accuracy: 0.7816 - val_loss: 1.0859 - val_accuracy: 0.5881\n",
            "Epoch 122/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5471 - accuracy: 0.7777\n",
            "Epoch 122: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5453 - accuracy: 0.7786 - val_loss: 1.0983 - val_accuracy: 0.5881\n",
            "Epoch 123/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5315 - accuracy: 0.7858\n",
            "Epoch 123: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5315 - accuracy: 0.7858 - val_loss: 1.0925 - val_accuracy: 0.5864\n",
            "Epoch 124/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5279 - accuracy: 0.7897\n",
            "Epoch 124: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5289 - accuracy: 0.7896 - val_loss: 1.1154 - val_accuracy: 0.5934\n",
            "Epoch 125/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5272 - accuracy: 0.7828\n",
            "Epoch 125: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5290 - accuracy: 0.7816 - val_loss: 1.1030 - val_accuracy: 0.5881\n",
            "Epoch 126/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5301 - accuracy: 0.7835\n",
            "Epoch 126: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5300 - accuracy: 0.7839 - val_loss: 1.1288 - val_accuracy: 0.5908\n",
            "Epoch 127/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5304 - accuracy: 0.7917\n",
            "Epoch 127: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5332 - accuracy: 0.7900 - val_loss: 1.0950 - val_accuracy: 0.5837\n",
            "Epoch 128/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5336 - accuracy: 0.7870\n",
            "Epoch 128: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5319 - accuracy: 0.7873 - val_loss: 1.1008 - val_accuracy: 0.5872\n",
            "Epoch 129/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5188 - accuracy: 0.7870\n",
            "Epoch 129: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5206 - accuracy: 0.7869 - val_loss: 1.0988 - val_accuracy: 0.5855\n",
            "Epoch 130/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5395 - accuracy: 0.7716\n",
            "Epoch 130: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5373 - accuracy: 0.7717 - val_loss: 1.0963 - val_accuracy: 0.5819\n",
            "Epoch 131/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5483 - accuracy: 0.7759\n",
            "Epoch 131: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5485 - accuracy: 0.7755 - val_loss: 1.0894 - val_accuracy: 0.5908\n",
            "Epoch 132/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5316 - accuracy: 0.7752\n",
            "Epoch 132: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5309 - accuracy: 0.7755 - val_loss: 1.0960 - val_accuracy: 0.5881\n",
            "Epoch 133/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5272 - accuracy: 0.7785\n",
            "Epoch 133: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5283 - accuracy: 0.7790 - val_loss: 1.1136 - val_accuracy: 0.5926\n",
            "Epoch 134/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5243 - accuracy: 0.7805\n",
            "Epoch 134: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5251 - accuracy: 0.7797 - val_loss: 1.0810 - val_accuracy: 0.5943\n",
            "Epoch 135/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5206 - accuracy: 0.7855\n",
            "Epoch 135: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5207 - accuracy: 0.7850 - val_loss: 1.1146 - val_accuracy: 0.5810\n",
            "Epoch 136/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5243 - accuracy: 0.7832\n",
            "Epoch 136: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5237 - accuracy: 0.7835 - val_loss: 1.1347 - val_accuracy: 0.5837\n",
            "Epoch 137/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5325 - accuracy: 0.7824\n",
            "Epoch 137: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5308 - accuracy: 0.7839 - val_loss: 1.0774 - val_accuracy: 0.5917\n",
            "Epoch 138/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5188 - accuracy: 0.7816\n",
            "Epoch 138: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5202 - accuracy: 0.7809 - val_loss: 1.0942 - val_accuracy: 0.5890\n",
            "Epoch 139/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5207 - accuracy: 0.7878\n",
            "Epoch 139: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5213 - accuracy: 0.7877 - val_loss: 1.1120 - val_accuracy: 0.5864\n",
            "Epoch 140/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5348 - accuracy: 0.7746\n",
            "Epoch 140: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5352 - accuracy: 0.7752 - val_loss: 1.0978 - val_accuracy: 0.5908\n",
            "Epoch 141/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5196 - accuracy: 0.7855\n",
            "Epoch 141: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5199 - accuracy: 0.7862 - val_loss: 1.1056 - val_accuracy: 0.5917\n",
            "Epoch 142/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4989 - accuracy: 0.7867\n",
            "Epoch 142: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4989 - accuracy: 0.7873 - val_loss: 1.1367 - val_accuracy: 0.5908\n",
            "Epoch 143/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.7877\n",
            "Epoch 143: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5228 - accuracy: 0.7877 - val_loss: 1.1232 - val_accuracy: 0.5934\n",
            "Epoch 144/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5070 - accuracy: 0.7863\n",
            "Epoch 144: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5095 - accuracy: 0.7850 - val_loss: 1.1643 - val_accuracy: 0.5899\n",
            "Epoch 145/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5154 - accuracy: 0.7812\n",
            "Epoch 145: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5151 - accuracy: 0.7820 - val_loss: 1.1366 - val_accuracy: 0.5899\n",
            "Epoch 146/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5124 - accuracy: 0.7890\n",
            "Epoch 146: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5105 - accuracy: 0.7904 - val_loss: 1.1633 - val_accuracy: 0.5979\n",
            "Epoch 147/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.5214 - accuracy: 0.7847\n",
            "Epoch 147: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5202 - accuracy: 0.7854 - val_loss: 1.1192 - val_accuracy: 0.5837\n",
            "Epoch 148/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5055 - accuracy: 0.7941\n",
            "Epoch 148: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5022 - accuracy: 0.7961 - val_loss: 1.1555 - val_accuracy: 0.5855\n",
            "Epoch 149/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4972 - accuracy: 0.7910\n",
            "Epoch 149: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4996 - accuracy: 0.7900 - val_loss: 1.1602 - val_accuracy: 0.5864\n",
            "Epoch 150/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4986 - accuracy: 0.7971\n",
            "Epoch 150: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4981 - accuracy: 0.7976 - val_loss: 1.1766 - val_accuracy: 0.5899\n",
            "Epoch 151/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5160 - accuracy: 0.7867\n",
            "Epoch 151: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5146 - accuracy: 0.7869 - val_loss: 1.1883 - val_accuracy: 0.5890\n",
            "Epoch 152/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5042 - accuracy: 0.7928\n",
            "Epoch 152: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5043 - accuracy: 0.7930 - val_loss: 1.1755 - val_accuracy: 0.5837\n",
            "Epoch 153/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5051 - accuracy: 0.7928\n",
            "Epoch 153: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.5046 - accuracy: 0.7926 - val_loss: 1.1414 - val_accuracy: 0.5864\n",
            "Epoch 154/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5106 - accuracy: 0.7949\n",
            "Epoch 154: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5101 - accuracy: 0.7930 - val_loss: 1.1298 - val_accuracy: 0.5890\n",
            "Epoch 155/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5022 - accuracy: 0.8014\n",
            "Epoch 155: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5022 - accuracy: 0.8014 - val_loss: 1.1705 - val_accuracy: 0.5943\n",
            "Epoch 156/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.4935 - accuracy: 0.7934\n",
            "Epoch 156: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4941 - accuracy: 0.7930 - val_loss: 1.1549 - val_accuracy: 0.5881\n",
            "Epoch 157/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.5084 - accuracy: 0.7924\n",
            "Epoch 157: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5104 - accuracy: 0.7911 - val_loss: 1.1365 - val_accuracy: 0.5952\n",
            "Epoch 158/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4929 - accuracy: 0.7953\n",
            "Epoch 158: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 2s 18ms/step - loss: 0.4929 - accuracy: 0.7953 - val_loss: 1.1636 - val_accuracy: 0.5908\n",
            "Epoch 159/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.5181 - accuracy: 0.7832\n",
            "Epoch 159: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.5184 - accuracy: 0.7843 - val_loss: 1.1221 - val_accuracy: 0.5881\n",
            "Epoch 160/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4862 - accuracy: 0.7984\n",
            "Epoch 160: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4868 - accuracy: 0.7979 - val_loss: 1.1700 - val_accuracy: 0.5908\n",
            "Epoch 161/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.7968\n",
            "Epoch 161: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4903 - accuracy: 0.7968 - val_loss: 1.1964 - val_accuracy: 0.5899\n",
            "Epoch 162/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.8033\n",
            "Epoch 162: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4826 - accuracy: 0.8033 - val_loss: 1.1649 - val_accuracy: 0.5837\n",
            "Epoch 163/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4893 - accuracy: 0.7965\n",
            "Epoch 163: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4912 - accuracy: 0.7964 - val_loss: 1.1797 - val_accuracy: 0.5810\n",
            "Epoch 164/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.8067\n",
            "Epoch 164: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4812 - accuracy: 0.8063 - val_loss: 1.1862 - val_accuracy: 0.5917\n",
            "Epoch 165/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4845 - accuracy: 0.8012\n",
            "Epoch 165: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4849 - accuracy: 0.8010 - val_loss: 1.1883 - val_accuracy: 0.5917\n",
            "Epoch 166/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4870 - accuracy: 0.7991\n",
            "Epoch 166: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4870 - accuracy: 0.7991 - val_loss: 1.1691 - val_accuracy: 0.5908\n",
            "Epoch 167/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4978 - accuracy: 0.7859\n",
            "Epoch 167: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 18ms/step - loss: 0.4988 - accuracy: 0.7850 - val_loss: 1.1799 - val_accuracy: 0.5952\n",
            "Epoch 168/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4902 - accuracy: 0.8056\n",
            "Epoch 168: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4885 - accuracy: 0.8052 - val_loss: 1.1605 - val_accuracy: 0.5917\n",
            "Epoch 169/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4885 - accuracy: 0.7994\n",
            "Epoch 169: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4886 - accuracy: 0.8002 - val_loss: 1.1765 - val_accuracy: 0.5899\n",
            "Epoch 170/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4836 - accuracy: 0.8109\n",
            "Epoch 170: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4846 - accuracy: 0.8090 - val_loss: 1.1723 - val_accuracy: 0.5855\n",
            "Epoch 171/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4824 - accuracy: 0.7984\n",
            "Epoch 171: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4818 - accuracy: 0.8006 - val_loss: 1.1658 - val_accuracy: 0.5908\n",
            "Epoch 172/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4795 - accuracy: 0.8031\n",
            "Epoch 172: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4814 - accuracy: 0.8021 - val_loss: 1.1757 - val_accuracy: 0.5917\n",
            "Epoch 173/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4942 - accuracy: 0.8017\n",
            "Epoch 173: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4937 - accuracy: 0.8017 - val_loss: 1.1492 - val_accuracy: 0.5934\n",
            "Epoch 174/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.4919 - accuracy: 0.7988\n",
            "Epoch 174: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4923 - accuracy: 0.7983 - val_loss: 1.1556 - val_accuracy: 0.5908\n",
            "Epoch 175/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4645 - accuracy: 0.8152\n",
            "Epoch 175: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4638 - accuracy: 0.8154 - val_loss: 1.1793 - val_accuracy: 0.5881\n",
            "Epoch 176/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.4695 - accuracy: 0.8022\n",
            "Epoch 176: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4700 - accuracy: 0.8021 - val_loss: 1.2131 - val_accuracy: 0.5819\n",
            "Epoch 177/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4780 - accuracy: 0.8106\n",
            "Epoch 177: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4756 - accuracy: 0.8116 - val_loss: 1.2094 - val_accuracy: 0.5846\n",
            "Epoch 178/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4926 - accuracy: 0.7948\n",
            "Epoch 178: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4907 - accuracy: 0.7972 - val_loss: 1.1903 - val_accuracy: 0.5881\n",
            "Epoch 179/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4608 - accuracy: 0.8063\n",
            "Epoch 179: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4639 - accuracy: 0.8048 - val_loss: 1.1991 - val_accuracy: 0.5881\n",
            "Epoch 180/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4848 - accuracy: 0.8110\n",
            "Epoch 180: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4862 - accuracy: 0.8105 - val_loss: 1.1909 - val_accuracy: 0.5837\n",
            "Epoch 181/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4726 - accuracy: 0.8059\n",
            "Epoch 181: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4724 - accuracy: 0.8059 - val_loss: 1.1957 - val_accuracy: 0.5872\n",
            "Epoch 182/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4737 - accuracy: 0.8016\n",
            "Epoch 182: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4695 - accuracy: 0.8044 - val_loss: 1.2070 - val_accuracy: 0.5864\n",
            "Epoch 183/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4768 - accuracy: 0.8031\n",
            "Epoch 183: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4757 - accuracy: 0.8040 - val_loss: 1.1817 - val_accuracy: 0.6023\n",
            "Epoch 184/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4670 - accuracy: 0.8048\n",
            "Epoch 184: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4674 - accuracy: 0.8040 - val_loss: 1.2318 - val_accuracy: 0.5899\n",
            "Epoch 185/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4816 - accuracy: 0.8066\n",
            "Epoch 185: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4802 - accuracy: 0.8067 - val_loss: 1.1880 - val_accuracy: 0.5828\n",
            "Epoch 186/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.8097\n",
            "Epoch 186: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4688 - accuracy: 0.8097 - val_loss: 1.2010 - val_accuracy: 0.5917\n",
            "Epoch 187/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4583 - accuracy: 0.8079\n",
            "Epoch 187: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4573 - accuracy: 0.8090 - val_loss: 1.2139 - val_accuracy: 0.5810\n",
            "Epoch 188/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.8109\n",
            "Epoch 188: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4638 - accuracy: 0.8109 - val_loss: 1.2328 - val_accuracy: 0.5837\n",
            "Epoch 189/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4607 - accuracy: 0.8125\n",
            "Epoch 189: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4574 - accuracy: 0.8147 - val_loss: 1.2649 - val_accuracy: 0.5864\n",
            "Epoch 190/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4769 - accuracy: 0.8016\n",
            "Epoch 190: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4775 - accuracy: 0.8025 - val_loss: 1.2027 - val_accuracy: 0.5934\n",
            "Epoch 191/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.8044\n",
            "Epoch 191: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4802 - accuracy: 0.8044 - val_loss: 1.1752 - val_accuracy: 0.5864\n",
            "Epoch 192/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.8040\n",
            "Epoch 192: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4792 - accuracy: 0.8044 - val_loss: 1.2218 - val_accuracy: 0.5926\n",
            "Epoch 193/200\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.4752 - accuracy: 0.8053\n",
            "Epoch 193: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4752 - accuracy: 0.8052 - val_loss: 1.2047 - val_accuracy: 0.5864\n",
            "Epoch 194/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4629 - accuracy: 0.8148\n",
            "Epoch 194: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4625 - accuracy: 0.8158 - val_loss: 1.2011 - val_accuracy: 0.5899\n",
            "Epoch 195/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4596 - accuracy: 0.8125\n",
            "Epoch 195: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4590 - accuracy: 0.8135 - val_loss: 1.2082 - val_accuracy: 0.5872\n",
            "Epoch 196/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4482 - accuracy: 0.8183\n",
            "Epoch 196: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4499 - accuracy: 0.8177 - val_loss: 1.2559 - val_accuracy: 0.5846\n",
            "Epoch 197/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.8048\n",
            "Epoch 197: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4665 - accuracy: 0.8044 - val_loss: 1.2225 - val_accuracy: 0.5890\n",
            "Epoch 198/200\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.7987\n",
            "Epoch 198: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4726 - accuracy: 0.7987 - val_loss: 1.2365 - val_accuracy: 0.6005\n",
            "Epoch 199/200\n",
            "80/83 [===========================>..] - ETA: 0s - loss: 0.4512 - accuracy: 0.8188\n",
            "Epoch 199: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.4512 - accuracy: 0.8196 - val_loss: 1.2232 - val_accuracy: 0.5899\n",
            "Epoch 200/200\n",
            "81/83 [============================>.] - ETA: 0s - loss: 0.4565 - accuracy: 0.8102\n",
            "Epoch 200: val_accuracy did not improve from 0.61205\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.4589 - accuracy: 0.8078 - val_loss: 1.2741 - val_accuracy: 0.5855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "best_model = keras.models.load_model(\"best_model1.hdf5\")"
      ],
      "metadata": {
        "id": "dnXIUOeAALPk"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ],
      "metadata": {
        "id": "G5r1a4CoAQoN",
        "outputId": "232f64ca-0faf-4078-f00c-a7ea15c81ea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 - 1s - loss: 1.0046 - accuracy: 0.6120 - 1s/epoch - 35ms/step\n",
            "Model accuracy:  0.6120460629463196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "pw_1i4JmBE97"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "L1iDVUHX-usW",
        "outputId": "ff1965d4-ae88-4d6f-e028-be5115430452"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.70      0.59       394\n",
            "           1       0.70      0.55      0.62       363\n",
            "           2       0.68      0.56      0.61       372\n",
            "\n",
            "    accuracy                           0.60      1129\n",
            "   macro avg       0.63      0.60      0.61      1129\n",
            "weighted avg       0.63      0.60      0.61      1129\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from plot_keras_history import show_history, plot_history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "show_history(history)\n",
        "plot_history(history, path=\"standard.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "sY5wq9z9GEY2",
        "outputId": "ea0bac26-c1ac-4d7a-fb42-10756bee8e26"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w-GTGB8E_sky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}