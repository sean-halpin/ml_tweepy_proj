{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm_text_sentiment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/ml_tweepy_proj/blob/main/svm_text_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "id": "zT5s9ms6s9ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install spellchecker\n",
        "!pip install pyspellchecker\n",
        "!pip install plot_keras_history"
      ],
      "metadata": {
        "id": "l_32RV-zeCXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "metadata": {
        "id": "FwEx4tlwsxq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def no_stopwords(text):\n",
        "  tokenwords = word_tokenize(text) \n",
        "  result = [w for w in tokenwords if not w in stop_words] \n",
        "  result = [] \n",
        "  for w in tokenwords: \n",
        "      if w not in stop_words: \n",
        "          result.append(w)\n",
        "  return \" \".join(result)"
      ],
      "metadata": {
        "id": "DsR1tpd2pQw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])"
      ],
      "metadata": {
        "id": "cza8vvcYrc_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output= string.punctuation\n",
        "print('list of punctuations:', output)"
      ],
      "metadata": {
        "id": "JNZIkIUslkTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_text_df(df):\n",
        "  df['tweet'] = df['tweet'].str.replace('http\\S+|www.\\S+|@.\\S+|&amp;.\\S+|<.*?>', '', case=False)\n",
        "  df['tweet'] = df['tweet'].str.lower()\n",
        "  df['tweet'] = df['tweet'].str.strip()\n",
        "  df['tweet'] = df['tweet'].str.translate(str.maketrans('', '', output))\n",
        "  df['lemmatized_tweet'] = df['tweet'].apply(lemmatize_text).apply(no_stopwords)\n",
        "  df = df.drop_duplicates('lemmatized_tweet', keep='last')\n",
        "  return df"
      ],
      "metadata": {
        "id": "aR2UvsKN-P1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_under_sample(X,y):\n",
        "  rus = RandomUnderSampler(random_state=0)\n",
        "  X_resampled, y_resampled = rus.fit_resample(X,y)\n",
        "  print(sorted(Counter(y_resampled).items()))\n",
        "  return X_resampled.flatten(), y_resampled.flatten()"
      ],
      "metadata": {
        "id": "biKHmIc4ZftK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_musk():\n",
        "  df = pd.read_csv(\"tweets_annotated.elon_musk.1651256232.csv\")\n",
        "  df = prepare_text_df(df)\n",
        "  X = df.lemmatized_tweet.values.reshape(-1,1)\n",
        "  y = df.sentiment.values.reshape(-1,1)\n",
        "  X_resampled, y_resampled = random_under_sample(X,y)\n",
        "  df_resampled = pd.DataFrame ({ 'lemmatized_tweet': X_resampled, 'sentiment': y_resampled})\n",
        "  return df_resampled"
      ],
      "metadata": {
        "id": "UbGJkBZWs0Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled = load_data_musk()"
      ],
      "metadata": {
        "id": "WIvaUyVoKG3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled.head()"
      ],
      "metadata": {
        "id": "RkY_CIBJdONZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "k0tVHkK0xMzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_resampled.lemmatized_tweet, df_resampled.sentiment, test_size=0.2, random_state=32)"
      ],
      "metadata": {
        "id": "yWYlxz8bx-Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classifier"
      ],
      "metadata": {
        "id": "hZnDCfyRvxnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer(max_features=1000)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=3, tol=None)),\n",
        "])\n",
        "\n",
        "text_clf.fit(X_train, y_train)\n",
        "\n",
        "predicted = text_clf.predict(X_test)\n",
        "np.mean(predicted == y_test)"
      ],
      "metadata": {
        "id": "FDeKiuRww5T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "def clf_metrics(y_test, predicted):\n",
        "  print(metrics.classification_report(y_test, predicted))\n",
        "  c_matrix = metrics.confusion_matrix(y_test, predicted)\n",
        "  ax = sns.heatmap(c_matrix, annot=True,      \n",
        "                    xticklabels=['negative','neutral','positive'],                \n",
        "                    yticklabels=['negative','neutral','positive'],                \n",
        "                  cbar=True, cmap='Blues', fmt='g')\n",
        "  ax.set_xlabel(\"Prediction\")\n",
        "  ax.set_ylabel(\"Actual\")"
      ],
      "metadata": {
        "id": "jvRncbECb6m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "\n",
        "def plot_learning_curve(\n",
        "    estimator,\n",
        "    title,\n",
        "    X,\n",
        "    y,\n",
        "    axes=None,\n",
        "    ylim=None,\n",
        "    cv=None,\n",
        "    n_jobs=None,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
        "):\n",
        "    if axes is None:\n",
        "        _, (ax) = plt.subplots(1, 1, figsize=(20, 5))\n",
        "\n",
        "    ax.set_title(title)\n",
        "    if ylim is not None:\n",
        "        ax.set_ylim(*ylim)\n",
        "    ax.set_xlabel(\"Training examples\")\n",
        "    ax.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
        "        estimator,\n",
        "        X,\n",
        "        y,\n",
        "        cv=cv,\n",
        "        n_jobs=n_jobs,\n",
        "        train_sizes=train_sizes,\n",
        "        return_times=True,\n",
        "    )\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    ax.grid()\n",
        "    ax.fill_between(\n",
        "        train_sizes,\n",
        "        train_scores_mean - train_scores_std,\n",
        "        train_scores_mean + train_scores_std,\n",
        "        alpha=0.1,\n",
        "        color=\"r\",\n",
        "    )\n",
        "    ax.fill_between(\n",
        "        train_sizes,\n",
        "        test_scores_mean - test_scores_std,\n",
        "        test_scores_mean + test_scores_std,\n",
        "        alpha=0.1,\n",
        "        color=\"g\",\n",
        "    )\n",
        "    ax.plot(\n",
        "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
        "    )\n",
        "    ax.plot(\n",
        "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
        "    )\n",
        "    ax.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "    return plt"
      ],
      "metadata": {
        "id": "9aJp7ZQr8NdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test, predicted)"
      ],
      "metadata": {
        "id": "x-aQ8UYec9ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curve(\n",
        "    text_clf, \"LC \", X=X_train, y=y_train,ylim=(0.1, 1.01), cv=5, n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "id": "rzLGkp55v4uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Classification Performance against another topic"
      ],
      "metadata": {
        "id": "7InFQ38LAe10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_formula_one():\n",
        "  df_f1 = pd.read_csv(\"tweets_annotated.mercedes_f1.1651259463.csv\")\n",
        "  df_f1 = prepare_text_df(df_f1)\n",
        "  X_f1 = df_f1.lemmatized_tweet.values.reshape(-1,1)\n",
        "  y_f1 = df_f1.sentiment.values.reshape(-1,1)\n",
        "  X_f1_resampled, y_f1_resampled = random_under_sample(X_f1,y_f1)\n",
        "  return pd.DataFrame ({ 'lemmatized_tweet': X_f1_resampled, 'sentiment': y_f1_resampled})"
      ],
      "metadata": {
        "id": "H3oIFOETK6bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_f1_resampled = load_data_formula_one()"
      ],
      "metadata": {
        "id": "fxDAbP7g9f3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_f1 = text_clf.predict(df_f1_resampled.lemmatized_tweet)"
      ],
      "metadata": {
        "id": "j-rQxfB7AQ8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(df_f1_resampled.sentiment, predicted_f1)"
      ],
      "metadata": {
        "id": "quFuNIqRArdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vader"
      ],
      "metadata": {
        "id": "qrMaqZMBvpqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "4IO2obn26CfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "def vader_sentiment(sentence):\n",
        "  vs = analyzer.polarity_scores(sentence)\n",
        "  comp = vs['compound']\n",
        "  if comp > 0.05:\n",
        "    return 'positive'\n",
        "  elif comp < -0.05:\n",
        "    return 'negative'\n",
        "  else:\n",
        "    return 'neutral'"
      ],
      "metadata": {
        "id": "rCMZRRrb5lNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vader_predicted = X_test.apply(vader_sentiment)"
      ],
      "metadata": {
        "id": "uiXINY-HefH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test, vader_predicted)"
      ],
      "metadata": {
        "id": "yv0Jd1scfCii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test[(y_test == \"neutral\") & (vader_predicted == \"positive\")])"
      ],
      "metadata": {
        "id": "sinyvvmZfley"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Neural Network Classifier"
      ],
      "metadata": {
        "id": "PbyiZMBA2JwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import gensim\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "VGraRTvu2M7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled = load_data_musk()"
      ],
      "metadata": {
        "id": "64a6tYr8JmtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labels_categorical(data):\n",
        "  labels = np.array(data)\n",
        "  y = []\n",
        "  for i in range(len(labels)):\n",
        "      if labels[i] == 'neutral':\n",
        "          y.append(0)\n",
        "      if labels[i] == 'negative':\n",
        "          y.append(1)\n",
        "      if labels[i] == 'positive':\n",
        "          y.append(2)\n",
        "  y = np.array(y)\n",
        "  labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "  del y\n",
        "  return labels"
      ],
      "metadata": {
        "id": "1SSI4v1k8J_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels_categorical(df_resampled.sentiment)"
      ],
      "metadata": {
        "id": "1gbZIrzF8s-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "\n",
        "max_words = 500\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df_resampled.lemmatized_tweet)\n",
        "sequences = tokenizer.texts_to_sequences(df_resampled.lemmatized_tweet)\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n",
        "print(tweets)"
      ],
      "metadata": {
        "id": "LTd9bp9gzSuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.3, random_state=32)"
      ],
      "metadata": {
        "id": "tq6zVGuA8xbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "cm3Mfpiq81CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding\n",
        "embedding_layer = Embedding(128, 16)\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(layers.Embedding(max_words, 12))\n",
        "model1.add(layers.LSTM(12,dropout=0.4, return_sequences=False))\n",
        "model1.add(layers.Dense(3,activation='softmax'))\n",
        "\n",
        "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4SY2V_ks3X7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "KOipYoR0APQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
        "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model1.fit(X_train, y_train, epochs=20,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
      ],
      "metadata": {
        "id": "KHjLziPmAyD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "best_model = keras.models.load_model(\"best_model1.hdf5\")"
      ],
      "metadata": {
        "id": "dnXIUOeAALPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ],
      "metadata": {
        "id": "G5r1a4CoAQoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "pw_1i4JmBE97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))"
      ],
      "metadata": {
        "id": "L1iDVUHX-usW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plot_keras_history import show_history, plot_history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "show_history(history)\n",
        "plot_history(history, path=\"standard.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "sY5wq9z9GEY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report - Model Comparison SVM vs. Vader"
      ],
      "metadata": {
        "id": "RpBvIOX742ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AZcL05qt42Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualisations"
      ],
      "metadata": {
        "id": "d2aIleAEYvyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"tweets_annotated.mercedes_f1.1651259463.csv\")"
      ],
      "metadata": {
        "id": "w-GTGB8E_sky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "bKwnLgu3sSB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['created_at'] = pd.to_datetime(df['created_at'])"
      ],
      "metadata": {
        "id": "RsvCVMQVspKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_df_5min = df.groupby(pd.Grouper(key='created_at', freq='30Min', convention='start')).size()\n",
        "tweet_df_5min.plot(figsize=(18,6))\n",
        "plt.ylabel('30 Minute Tweet Count')\n",
        "plt.title('Formula One Tweet Freq. Count')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "tKzZ5vhwg4k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "v9JPNwTesbBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_text_for_wordcloud(df):\n",
        "  df['cleaned_tweet'] = df['tweet'].str.replace('https\\S+|http\\S+|www.\\S+|@.\\S+|&amp;.\\S+|<.*?>', '', case=False)\n",
        "  df['cleaned_tweet'] = df['cleaned_tweet'].str.lower()\n",
        "  df['cleaned_tweet'] = df['cleaned_tweet'].str.strip()\n",
        "  df['normalized_tweet'] = df['cleaned_tweet'].str.translate(str.maketrans('', '', output))\n",
        "  df['normalized_tweet'] = df['normalized_tweet'].apply(no_stopwords)\n",
        "  return df"
      ],
      "metadata": {
        "id": "ML9YL24nwOKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud_df = prep_text_for_wordcloud(df)"
      ],
      "metadata": {
        "id": "V9KVfjCzwwM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_wordcloud(wc_title, series):\n",
        "  wordcloud = WordCloud(width=800, height=400, margin=2).generate(' '.join(series))\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title(wc_title)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(wordcloud)"
      ],
      "metadata": {
        "id": "zZ8z8G9Pw42_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashtag_counts = df.tweet.str.extractall(r'(\\#\\w+)')[0].value_counts()"
      ],
      "metadata": {
        "id": "rtFzVzV89xYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_hashtags = hashtag_counts[:10]"
      ],
      "metadata": {
        "id": "FA8XTzm_AffL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "keys = top_hashtags.keys().to_list()\n",
        "values = list(top_hashtags.array)\n",
        "ax.bar(keys,values)\n",
        "plt.title(\"Most Common Hashtags\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Hashtag\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JZLcjjvZ-pMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_tweets = wordcloud_df[wordcloud_df[\"sentiment\"] == \"positive\"]['normalized_tweet']\n",
        "neutral_tweets = wordcloud_df[wordcloud_df[\"sentiment\"] == \"neutral\"]['normalized_tweet']\n",
        "negative_tweets = wordcloud_df[wordcloud_df[\"sentiment\"] == \"negative\"]['normalized_tweet']\n",
        "tweets_with_likes = wordcloud_df[wordcloud_df[\"like_count\"] > 10]['normalized_tweet']\n",
        "tweets_with_retweets = wordcloud_df[wordcloud_df[\"retweet_count\"] > 5]['normalized_tweet']"
      ],
      "metadata": {
        "id": "iAEFq71J2OQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tweets_with_retweets)"
      ],
      "metadata": {
        "id": "_tLwS2R-4pRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_wordcloud(\"All Formula One Tweets - Wordcloud\", wordcloud_df['normalized_tweet'])\n",
        "create_wordcloud(\"Positive Formula One Tweets - Wordcloud\",  positive_tweets)\n",
        "create_wordcloud(\"Neutral Formula One Tweets - Wordcloud\",  neutral_tweets)\n",
        "create_wordcloud(\"Negative Formula One Tweets - Wordcloud\",  negative_tweets)\n",
        "create_wordcloud(\"Liked Formula One Tweets - Wordcloud\",  tweets_with_likes)\n",
        "create_wordcloud(\"Retweeted Formula One Tweets - Wordcloud\",  tweets_with_retweets)"
      ],
      "metadata": {
        "id": "C-pBF9HSw_gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "from shapely.geometry import mapping, shape\n",
        "from shapely.prepared import prep\n",
        "from shapely.geometry import Point\n",
        "\n",
        "\n",
        "data = requests.get(\n",
        "    \"https://raw.githubusercontent.com/datasets/geo-countries/master/data/countries.geojson\").json()\n",
        "\n",
        "countries = {}\n",
        "for feature in data[\"features\"]:\n",
        "    geom = feature[\"geometry\"]\n",
        "    country = feature[\"properties\"][\"ADMIN\"]\n",
        "    countries[country] = prep(shape(geom))\n",
        "\n",
        "def get_country(lon, lat):\n",
        "    point = Point(lon, lat)\n",
        "    for country, geom in countries.items():\n",
        "        if geom.contains(point):\n",
        "            return country\n",
        "\n",
        "    return \"unknown\""
      ],
      "metadata": {
        "id": "LswVCB426Yp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "def create_wordcloud(series):\n",
        "  wordcloud = WordCloud(width=800, height=400, margin=2).generate(' '.join(series))\n",
        "  return wordcloud.to_image()"
      ],
      "metadata": {
        "id": "9Br1sy5e60zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def no_stopwords(text):\n",
        "    tokenwords = word_tokenize(text)\n",
        "    result = [w for w in tokenwords if not w in stop_words]\n",
        "    result = []\n",
        "    for w in tokenwords:\n",
        "        if w not in stop_words:\n",
        "            result.append(w)\n",
        "    return \" \".join(result)\n",
        "\n",
        "\n",
        "def prep_text(df):\n",
        "    df['sentiment_category'] = df['sentiment'].astype('category')\n",
        "    df['sentiment_numeric'] = pd.factorize(df['sentiment_category'])[0]\n",
        "    df['cleaned_tweet'] = df['tweet'].str.replace(\n",
        "        'https\\S+|http\\S+|www.\\S+|@.\\S+|&amp;.\\S+|<.*?>', '', case=False)\n",
        "    df['cleaned_tweet'] = df['cleaned_tweet'].str.lower()\n",
        "    df['cleaned_tweet'] = df['cleaned_tweet'].str.strip()\n",
        "    df['normalized_tweet'] = df['cleaned_tweet'].str.translate(\n",
        "        str.maketrans('', '', string.punctuation))\n",
        "    df['normalized_tweet'] = df['normalized_tweet'].apply(no_stopwords)\n",
        "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "    df['country'] = df.apply(\n",
        "        lambda x: get_country(x['long'], x['lat']), axis=1)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "Aqi3bTus6SXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U kaleido"
      ],
      "metadata": {
        "id": "H9zKJ_Ai8q6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "# df = pd.read_csv(\"tweets_annotated.1650575029.formulaone.csv\")\n",
        "df = pd.read_csv(\"tweets_annotated.elon_musk.1651256232.csv\")\n",
        "df = prep_text(df)\n",
        "\n",
        "# Line - Tweets Over Time Buckets\n",
        "tweet_df_buckets = df.groupby(pd.Grouper(\n",
        "    key='created_at', freq='5Min', convention='start')).size()\n",
        "df_t = pd.DataFrame(list(tweet_df_buckets.items()),\n",
        "                    columns=['created_at', 'counts'])\n",
        "fig_buckets = px.line(\n",
        "    df_t,\n",
        "    x=\"created_at\",\n",
        "    y=\"counts\",\n",
        "    title=\"Tweet Counts in 5 minute buckets\",\n",
        "    labels={\n",
        "        'created_at': 'Time',\n",
        "        'counts': 'Count'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Lines - Tweet Sentiment Counts in 60 minute Time Buckets\n",
        "tweet_sentiment_time_buckets = df.groupby([\n",
        "    'sentiment',\n",
        "    pd.Grouper(\n",
        "        key='created_at', freq='5Min', convention='start')\n",
        "]).size()\n",
        "df_t_s = tweet_sentiment_time_buckets.reset_index(name='counts')\n",
        "\n",
        "fig_tweet_sentiment_time_buckets = px.line(\n",
        "    df_t_s,\n",
        "    line_group=\"sentiment\",\n",
        "    color=\"sentiment\",\n",
        "    x=\"created_at\",\n",
        "    y=\"counts\",\n",
        "    title=\"Tweet Sentiment Counts in 5 minute Time Buckets\",\n",
        "    labels={\n",
        "        'created_at': 'Time',\n",
        "        'sentiment': 'Sentiment',\n",
        "        'counts': 'Count'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Pie - Sentiment\n",
        "df_sent_counts = df['sentiment'].value_counts().reset_index(name='counts')\n",
        "fig_pie_overall_sent = px.pie(\n",
        "    df_sent_counts,\n",
        "    values='counts',\n",
        "    names='index',\n",
        "    title='Overall Sentiment Pie Chart',\n",
        "    hole=0.2,\n",
        "    labels={\n",
        "        'index': 'Sentiment',\n",
        "        'counts': 'Count'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Chloropleth - Median Tweet Sentiment by Country\n",
        "tweet_most_common_sentiment_by_country = df.groupby(\n",
        "    'country')['sentiment_numeric'].mean().reset_index(name='sentiment_mean')\n",
        "fig_chloro_average_sentiment = px.choropleth(\n",
        "    tweet_most_common_sentiment_by_country,\n",
        "    locations=\"country\",\n",
        "    locationmode=\"country names\",\n",
        "    projection=\"natural earth\",\n",
        "    hover_name=\"country\",\n",
        "    color=\"sentiment_mean\",\n",
        "    color_continuous_scale='aggrnyl',\n",
        "    color_continuous_midpoint=0.4,\n",
        "    title=\"Sentiment Positivity by Country\",\n",
        "    labels={\n",
        "        'country': 'Country',\n",
        "        'sentiment_mean': 'Sentiment Positivity',\n",
        "        'counts': 'Count'\n",
        "    },\n",
        "    width=1500,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "# Sunburst sentiments by platform\n",
        "tweet_sentiments_by_source = df.groupby(['source', 'sentiment'])['sentiment'].count().reset_index(name='count')\n",
        "top_platforms = df['source'].value_counts()[:5].to_frame().reset_index()['index'].to_list()\n",
        "tweet_sentiments_by_platform_top = tweet_sentiments_by_source[tweet_sentiments_by_source['source'].isin(top_platforms)]\n",
        "fig_sunb = px.sunburst(\n",
        "    tweet_sentiments_by_platform_top,\n",
        "    path=[\"source\", \"sentiment\"],\n",
        "    values='count',\n",
        "    height=1000,\n",
        "    title='Sentiment Counts per Platform',\n",
        "    color='sentiment'\n",
        ")\n",
        "\n",
        "# Treemap\n",
        "fig_treemap = px.treemap(\n",
        "    tweet_sentiments_by_platform_top,\n",
        "    path=[\"source\", \"sentiment\"],\n",
        "    height=1000,\n",
        "    title='Sentiment Counts per Platform',\n",
        "    color='sentiment',\n",
        "    values='count'\n",
        ")\n",
        "\n",
        "# Geo - Tweet Counts\n",
        "df_country_counts = df['country'].value_counts().reset_index(name='counts')\n",
        "# print(df_country_counts)\n",
        "fig_geo_tweet_counts = px.scatter_geo(\n",
        "    df_country_counts,\n",
        "    locations=\"index\",\n",
        "    locationmode=\"country names\",\n",
        "    size=\"counts\",\n",
        "    projection=\"natural earth\",\n",
        "    hover_name=\"index\",\n",
        "    color=\"index\",\n",
        "    title=\"Relative Tweet Count per Country\",\n",
        "    labels={\n",
        "        'index': 'Country',\n",
        "        'counts': 'Count'\n",
        "    },\n",
        "    width=1500,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "# Most popular hashtags\n",
        "hashtag_counts = df.tweet.str.extractall(\n",
        "    r'(\\#\\w+)')[0].value_counts().reset_index(name='counts')\n",
        "fig_popular_hashtags = px.bar(\n",
        "    hashtag_counts[hashtag_counts.counts > 10][:10],\n",
        "    x='index',\n",
        "    y='counts',\n",
        "    color='counts',\n",
        "    title=\"Most Popular Hashtags\",\n",
        "    labels={\n",
        "        'index': 'Hashtag',\n",
        "        'counts': 'Count'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Wordcloud\n",
        "fig_worldcloud = px.imshow(\n",
        "    create_wordcloud(df['normalized_tweet']),\n",
        "    title=\"Wordcloud\"\n",
        ")\n",
        "\n",
        "# Bar - Mean Tweet Sentiment by Platform\n",
        "most_frequent_platforms = df['source'].value_counts()[:10].index.tolist()\n",
        "tweet_most_common_sentiment_by_platform = df[df['source'].isin(most_frequent_platforms)].groupby(\n",
        "    'source')['sentiment_numeric'].mean().reset_index(name='sentiment_mean')\n",
        "fig_tweet_most_common_sentiment_by_platform = px.bar(\n",
        "    tweet_most_common_sentiment_by_platform.sort_values(by=['sentiment_mean']),\n",
        "    x='source',\n",
        "    y='sentiment_mean',\n",
        "    color='source',\n",
        "    color_continuous_scale='thermal',\n",
        "    title=\"Average Sentiment Positivity by Platform\",\n",
        "    labels={\n",
        "        'source': 'Platform',\n",
        "        'sentiment_mean': 'Sentiment Positivity',\n",
        "    }\n",
        ")\n",
        "\n",
        "# Mabox Density\n",
        "fig_rel = px.density_mapbox(\n",
        "    df, lat='lat', lon='long', z='reliability', radius=10,\n",
        "    center=dict(lat=0, lon=180), zoom=0,\n",
        "    mapbox_style=\"stamen-terrain\"\n",
        ")\n",
        "\n",
        "# Chloropleth - Median Tweet Reliability by Country\n",
        "tweet_avg_reliability_by_country = df.groupby(\n",
        "    'country')['reliability'].mean().reset_index(name='reliability_mean')\n",
        "fig_chloro_average_reliability = px.choropleth(\n",
        "    tweet_avg_reliability_by_country,\n",
        "    locations=\"country\",\n",
        "    locationmode=\"country names\",\n",
        "    projection=\"natural earth\",\n",
        "    hover_name=\"country\",\n",
        "    color=\"reliability_mean\",\n",
        "    color_continuous_scale='thermal',\n",
        "    color_continuous_midpoint=0.7,\n",
        "    title=\"Mean Reliability by Country\",\n",
        "    labels={\n",
        "        'country': 'Country',\n",
        "        'reliability_mean': 'Reliability',\n",
        "        'counts': 'Count'\n",
        "    },\n",
        "    width=1500,\n",
        "    height=800\n",
        ")"
      ],
      "metadata": {
        "id": "Sucex9sgHeEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_buckets.show(renderer=\"colab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "tVPwj5f_6dyH",
        "outputId": "32f74d8f-5815-40d5-ab8c-32f7acaafc07"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"c817b709-4bf1-4648-bf2d-146a7f8b9618\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c817b709-4bf1-4648-bf2d-146a7f8b9618\")) {                    Plotly.newPlot(                        \"c817b709-4bf1-4648-bf2d-146a7f8b9618\",                        [{\"hovertemplate\":\"Time=%{x}<br>Count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[\"2022-04-29T14:30:00+00:00\",\"2022-04-29T14:35:00+00:00\",\"2022-04-29T14:40:00+00:00\",\"2022-04-29T14:45:00+00:00\",\"2022-04-29T14:50:00+00:00\",\"2022-04-29T14:55:00+00:00\",\"2022-04-29T15:00:00+00:00\",\"2022-04-29T15:05:00+00:00\",\"2022-04-29T15:10:00+00:00\",\"2022-04-29T15:15:00+00:00\",\"2022-04-29T15:20:00+00:00\",\"2022-04-29T15:25:00+00:00\",\"2022-04-29T15:30:00+00:00\",\"2022-04-29T15:35:00+00:00\",\"2022-04-29T15:40:00+00:00\",\"2022-04-29T15:45:00+00:00\",\"2022-04-29T15:50:00+00:00\",\"2022-04-29T15:55:00+00:00\",\"2022-04-29T16:00:00+00:00\",\"2022-04-29T16:05:00+00:00\",\"2022-04-29T16:10:00+00:00\",\"2022-04-29T16:15:00+00:00\",\"2022-04-29T16:20:00+00:00\",\"2022-04-29T16:25:00+00:00\",\"2022-04-29T16:30:00+00:00\",\"2022-04-29T16:35:00+00:00\",\"2022-04-29T16:40:00+00:00\",\"2022-04-29T16:45:00+00:00\",\"2022-04-29T16:50:00+00:00\",\"2022-04-29T16:55:00+00:00\",\"2022-04-29T17:00:00+00:00\",\"2022-04-29T17:05:00+00:00\",\"2022-04-29T17:10:00+00:00\",\"2022-04-29T17:15:00+00:00\",\"2022-04-29T17:20:00+00:00\",\"2022-04-29T17:25:00+00:00\",\"2022-04-29T17:30:00+00:00\"],\"xaxis\":\"x\",\"y\":[138,285,281,290,276,261,321,266,288,282,286,276,298,316,330,266,282,286,333,335,270,288,288,282,337,286,341,331,322,314,285,256,298,315,339,317,103],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Time\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Tweet Counts in 5 minute buckets\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c817b709-4bf1-4648-bf2d-146a7f8b9618');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iPgPjrfe7JsN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}