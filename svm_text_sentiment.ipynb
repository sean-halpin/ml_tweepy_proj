{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm_text_sentiment.ipynb",
      "provenance": [],
      "mount_file_id": "1bpJik2FL13Sd2YXfH09APwYmr28ITcv-",
      "authorship_tag": "ABX9TyNbkyNLScQaa6JDsMZalNHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/ml_tweepy_proj/blob/main/svm_text_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install spellchecker\n",
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "id": "l_32RV-zeCXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "id": "zT5s9ms6s9ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem.wordnet import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "FwEx4tlwsxq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"tweets_annotated.1650577206.elonmusk.csv\")"
      ],
      "metadata": {
        "id": "UbGJkBZWs0Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spelling = SpellChecker()\n",
        "def spelling_checks(text):\n",
        "    correct_result = []\n",
        "    typo_words = spelling.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in typo_words:\n",
        "            correct_result.append(spelling.correction(word))\n",
        "        else:\n",
        "            correct_result.append(word)\n",
        "    return \" \".join(correct_result)"
      ],
      "metadata": {
        "id": "Vqw2oVJZms7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def no_stopwords(text):\n",
        "  tokenwords = word_tokenize(text) \n",
        "  result = [w for w in tokenwords if not w in stop_words] \n",
        "  result = [] \n",
        "  for w in tokenwords: \n",
        "      if w not in stop_words: \n",
        "          result.append(w)\n",
        "  return \" \".join(result)"
      ],
      "metadata": {
        "id": "DsR1tpd2pQw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])"
      ],
      "metadata": {
        "id": "cza8vvcYrc_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output= string.punctuation\n",
        "print('list of punctuations:', output)"
      ],
      "metadata": {
        "id": "JNZIkIUslkTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'] = df['tweet'].str.replace('http\\S+|www.\\S+|@.\\S+|&amp;.\\S+|<.*?>', '', case=False)\n",
        "df['tweet'] = df['tweet'].str.lower()\n",
        "df['tweet'] = df['tweet'].str.strip()\n",
        "df['tweet'] = df['tweet'].str.translate(str.maketrans('', '', output))\n",
        "df['lemmatized_tweet'] = df['tweet'].apply(lemmatize_text).apply(no_stopwords)"
      ],
      "metadata": {
        "id": "9GbavaxZZG9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates('tweet', keep='last')"
      ],
      "metadata": {
        "id": "Z3DEAihohlOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.lemmatized_tweet.values.reshape(-1,1)\n",
        "y = df.sentiment.values.reshape(-1,1)"
      ],
      "metadata": {
        "id": "QyOGzEB9ZsKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "X_resampled, y_resampled = rus.fit_resample(X,y)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "metadata": {
        "id": "biKHmIc4ZftK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled = pd.DataFrame ({ 'lemmatized_tweet': X_resampled.flatten(), 'sentiment': y_resampled})"
      ],
      "metadata": {
        "id": "C-GzbM90bJaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled.head()"
      ],
      "metadata": {
        "id": "RkY_CIBJdONZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "k0tVHkK0xMzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_resampled.lemmatized_tweet, df_resampled.sentiment, test_size=0.3, random_state=32)"
      ],
      "metadata": {
        "id": "yWYlxz8bx-Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None)),\n",
        "])\n",
        "\n",
        "text_clf.fit(X_train, y_train)\n",
        "\n",
        "predicted = text_clf.predict(X_test)\n",
        "np.mean(predicted == y_test)"
      ],
      "metadata": {
        "id": "FDeKiuRww5T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "def clf_metrics(y_test, predicted):\n",
        "  print(metrics.classification_report(y_test, predicted))\n",
        "  c_matrix = metrics.confusion_matrix(y_test, predicted)\n",
        "  ax = sns.heatmap(c_matrix, annot=True,      \n",
        "                    xticklabels=['negative','neutral','positive'],                \n",
        "                    yticklabels=['negative','neutral','positive'],                \n",
        "                  cbar=True, cmap='Blues', fmt='g')\n",
        "  ax.set_xlabel(\"Prediction\")\n",
        "  ax.set_ylabel(\"Actual\")"
      ],
      "metadata": {
        "id": "jvRncbECb6m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test, predicted)"
      ],
      "metadata": {
        "id": "x-aQ8UYec9ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "4IO2obn26CfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "def vader_sentiment(sentence):\n",
        "  vs = analyzer.polarity_scores(sentence)\n",
        "  comp = vs['compound']\n",
        "  if comp > 0.05:\n",
        "    return 'positive'\n",
        "  elif comp < -0.05:\n",
        "    return 'negative'\n",
        "  else:\n",
        "    return 'neutral'"
      ],
      "metadata": {
        "id": "rCMZRRrb5lNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vader_predicted = X_test.apply(vader_sentiment)"
      ],
      "metadata": {
        "id": "uiXINY-HefH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics(y_test, vader_predicted)"
      ],
      "metadata": {
        "id": "yv0Jd1scfCii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('max_colwidth', -1)"
      ],
      "metadata": {
        "id": "ngp9I54_kS4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test[(y_test == \"neutral\") & (vader_predicted == \"positive\")])"
      ],
      "metadata": {
        "id": "sinyvvmZfley"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[(y_test == \"neutral\") & (vader_predicted == \"positive\")]"
      ],
      "metadata": {
        "id": "VgszAVv-h9u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K2_AzqkDkKkp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}