{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_dnn_text_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/ml_tweepy_proj/blob/main/keras_dnn_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT5s9ms6s9ts",
        "outputId": "4dcbdc32-3e03-49fb-8d06-c89f23e319e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import gensim\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "FwEx4tlwsxq-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"tweets_annotated.1646773409.csv\")"
      ],
      "metadata": {
        "id": "UbGJkBZWs0Gy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "D_gyZ4q42YnA",
        "outputId": "ddfdd662-2cdd-4a3a-a375-bf8fc5761012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c6fb14f4-1268-4956-bde6-8d2b857b4458\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I want to know why the first round is branded ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@DebbieW51726281 Hi there, this will be back o...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6fb14f4-1268-4956-bde6-8d2b857b4458')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6fb14f4-1268-4956-bde6-8d2b857b4458 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6fb14f4-1268-4956-bde6-8d2b857b4458');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               tweet sentiment\n",
              "0  I want to know why the first round is branded ...  negative\n",
              "1  @DebbieW51726281 Hi there, this will be back o...   neutral"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('sentiment').nunique()"
      ],
      "metadata": {
        "id": "XEPfHaLA92Wi",
        "outputId": "d847f7dd-98a1-400e-8f00-a25db9762067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-23323819-7710-4c2e-9fdf-6b3e39e9ad75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>405</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23323819-7710-4c2e-9fdf-6b3e39e9ad75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23323819-7710-4c2e-9fdf-6b3e39e9ad75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23323819-7710-4c2e-9fdf-6b3e39e9ad75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           tweet\n",
              "sentiment       \n",
              "negative     229\n",
              "neutral     1361\n",
              "positive     405"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "7C3Yh0Xv-CsT",
        "outputId": "b3beb374-4f14-4fa4-d70d-638d6a659bd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet        0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def depure_data(data):\n",
        "    \n",
        "    #Removing URLs with a regular expression\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    data = url_pattern.sub(r'', data)\n",
        "\n",
        "    # Remove Emails\n",
        "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
        "\n",
        "    # Remove new line characters\n",
        "    data = re.sub('\\s+', ' ', data)\n",
        "\n",
        "    # Remove distracting single quotes\n",
        "    data = re.sub(\"\\'\", \"\", data)\n",
        "        \n",
        "    return data"
      ],
      "metadata": {
        "id": "aU7acmUbyW2F"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence),     deacc=True))"
      ],
      "metadata": {
        "id": "R-k_JEW4ycl0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detokenize(text):\n",
        "    return TreebankWordDetokenizer().detokenize(text)"
      ],
      "metadata": {
        "id": "DoFl--TJy8U8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labels_categorical(data):\n",
        "  labels = np.array(data)\n",
        "  y = []\n",
        "  for i in range(len(labels)):\n",
        "      if labels[i] == 'neutral':\n",
        "          y.append(0)\n",
        "      if labels[i] == 'negative':\n",
        "          y.append(1)\n",
        "      if labels[i] == 'positive':\n",
        "          y.append(2)\n",
        "  y = np.array(y)\n",
        "  labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "  del y\n",
        "  return labels"
      ],
      "metadata": {
        "id": "1SSI4v1k8J_t"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels_categorical(df.sentiment)"
      ],
      "metadata": {
        "id": "1gbZIrzF8s-M"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df.tweet)\n",
        "sequences = tokenizer.texts_to_sequences(df.tweet)\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n",
        "print(tweets)"
      ],
      "metadata": {
        "id": "LTd9bp9gzSuk",
        "outputId": "d7cb0fff-2bd3-4ae9-bc8a-88882d8d5322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ...    1    2 1791]\n",
            " [   0    0    0 ...  181 1134  588]\n",
            " [   0    0    0 ...    1    2 1798]\n",
            " ...\n",
            " [   0    0    0 ...    1    2   25]\n",
            " [   0    0    0 ...   39   38   41]\n",
            " [   0    0    0 ...    1    2   27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.3, random_state=32)"
      ],
      "metadata": {
        "id": "vd15-FVS1MJP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding\n",
        "embedding_layer = Embedding(1000, 64)\n",
        "model1 = Sequential()\n",
        "model1.add(layers.Embedding(max_words, 20))\n",
        "model1.add(layers.LSTM(15,dropout=0.5))\n",
        "model1.add(layers.Dense(3,activation='softmax'))\n",
        "\n",
        "\n",
        "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
        "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
      ],
      "metadata": {
        "id": "4SY2V_ks3X7H",
        "outputId": "1d39d02f-9a44-4cb7-972b-93d1dc15217f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.8476 - accuracy: 0.6736\n",
            "Epoch 1: val_accuracy improved from -inf to 0.68500, saving model to best_model1.hdf5\n",
            "44/44 [==============================] - 6s 93ms/step - loss: 0.8476 - accuracy: 0.6736 - val_loss: 0.5989 - val_accuracy: 0.6850\n",
            "Epoch 2/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.5720 - accuracy: 0.7614\n",
            "Epoch 2: val_accuracy improved from 0.68500 to 0.82500, saving model to best_model1.hdf5\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.5720 - accuracy: 0.7614 - val_loss: 0.5178 - val_accuracy: 0.8250\n",
            "Epoch 3/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.4931 - accuracy: 0.8171\n",
            "Epoch 3: val_accuracy improved from 0.82500 to 0.83000, saving model to best_model1.hdf5\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.4931 - accuracy: 0.8171 - val_loss: 0.4529 - val_accuracy: 0.8300\n",
            "Epoch 4/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.4325 - accuracy: 0.8479\n",
            "Epoch 4: val_accuracy improved from 0.83000 to 0.83833, saving model to best_model1.hdf5\n",
            "44/44 [==============================] - 3s 80ms/step - loss: 0.4325 - accuracy: 0.8479 - val_loss: 0.4010 - val_accuracy: 0.8383\n",
            "Epoch 5/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.8636\n",
            "Epoch 5: val_accuracy did not improve from 0.83833\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.3703 - accuracy: 0.8636 - val_loss: 0.3886 - val_accuracy: 0.8300\n",
            "Epoch 6/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.8843\n",
            "Epoch 6: val_accuracy improved from 0.83833 to 0.84833, saving model to best_model1.hdf5\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.3193 - accuracy: 0.8843 - val_loss: 0.3628 - val_accuracy: 0.8483\n",
            "Epoch 7/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.8779\n",
            "Epoch 7: val_accuracy did not improve from 0.84833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.3626 - accuracy: 0.8779 - val_loss: 0.3552 - val_accuracy: 0.8483\n",
            "Epoch 8/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.9057\n",
            "Epoch 8: val_accuracy did not improve from 0.84833\n",
            "44/44 [==============================] - 3s 77ms/step - loss: 0.2518 - accuracy: 0.9057 - val_loss: 0.3622 - val_accuracy: 0.8467\n",
            "Epoch 9/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.9207\n",
            "Epoch 9: val_accuracy did not improve from 0.84833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.2233 - accuracy: 0.9207 - val_loss: 0.3684 - val_accuracy: 0.8317\n",
            "Epoch 10/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.1988 - accuracy: 0.9293\n",
            "Epoch 10: val_accuracy did not improve from 0.84833\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.1988 - accuracy: 0.9293 - val_loss: 0.3686 - val_accuracy: 0.8417\n",
            "Epoch 11/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9407\n",
            "Epoch 11: val_accuracy did not improve from 0.84833\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.1886 - accuracy: 0.9407 - val_loss: 0.3834 - val_accuracy: 0.8467\n",
            "Epoch 12/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.1667 - accuracy: 0.9443\n",
            "Epoch 12: val_accuracy improved from 0.84833 to 0.85000, saving model to best_model1.hdf5\n",
            "44/44 [==============================] - 4s 93ms/step - loss: 0.1667 - accuracy: 0.9443 - val_loss: 0.4162 - val_accuracy: 0.8500\n",
            "Epoch 13/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9514\n",
            "Epoch 13: val_accuracy improved from 0.85000 to 0.85833, saving model to best_model1.hdf5\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.1470 - accuracy: 0.9514 - val_loss: 0.4353 - val_accuracy: 0.8583\n",
            "Epoch 14/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.9514\n",
            "Epoch 14: val_accuracy did not improve from 0.85833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.1428 - accuracy: 0.9514 - val_loss: 0.4423 - val_accuracy: 0.8483\n",
            "Epoch 15/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9707\n",
            "Epoch 15: val_accuracy did not improve from 0.85833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.1169 - accuracy: 0.9707 - val_loss: 0.4396 - val_accuracy: 0.8533\n",
            "Epoch 16/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9721\n",
            "Epoch 16: val_accuracy did not improve from 0.85833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0972 - accuracy: 0.9721 - val_loss: 0.4087 - val_accuracy: 0.8583\n",
            "Epoch 17/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9771\n",
            "Epoch 17: val_accuracy did not improve from 0.85833\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.0792 - accuracy: 0.9771 - val_loss: 0.4161 - val_accuracy: 0.8583\n",
            "Epoch 18/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9821\n",
            "Epoch 18: val_accuracy improved from 0.85833 to 0.86333, saving model to best_model1.hdf5\n",
            "44/44 [==============================] - 4s 89ms/step - loss: 0.0744 - accuracy: 0.9821 - val_loss: 0.4585 - val_accuracy: 0.8633\n",
            "Epoch 19/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9850\n",
            "Epoch 19: val_accuracy did not improve from 0.86333\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0570 - accuracy: 0.9850 - val_loss: 0.4609 - val_accuracy: 0.8533\n",
            "Epoch 20/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9829\n",
            "Epoch 20: val_accuracy did not improve from 0.86333\n",
            "44/44 [==============================] - 3s 80ms/step - loss: 0.0478 - accuracy: 0.9829 - val_loss: 0.4465 - val_accuracy: 0.8550\n",
            "Epoch 21/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9886\n",
            "Epoch 21: val_accuracy improved from 0.86333 to 0.86833, saving model to best_model1.hdf5\n",
            "44/44 [==============================] - 4s 90ms/step - loss: 0.0445 - accuracy: 0.9886 - val_loss: 0.4723 - val_accuracy: 0.8683\n",
            "Epoch 22/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9871\n",
            "Epoch 22: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.0402 - accuracy: 0.9871 - val_loss: 0.4746 - val_accuracy: 0.8567\n",
            "Epoch 23/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9907\n",
            "Epoch 23: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 0.4965 - val_accuracy: 0.8667\n",
            "Epoch 24/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9914\n",
            "Epoch 24: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0312 - accuracy: 0.9914 - val_loss: 0.5199 - val_accuracy: 0.8633\n",
            "Epoch 25/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9900\n",
            "Epoch 25: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.5752 - val_accuracy: 0.8600\n",
            "Epoch 26/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9964\n",
            "Epoch 26: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.5495 - val_accuracy: 0.8633\n",
            "Epoch 27/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9929\n",
            "Epoch 27: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.5453 - val_accuracy: 0.8583\n",
            "Epoch 28/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9979\n",
            "Epoch 28: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.5855 - val_accuracy: 0.8650\n",
            "Epoch 29/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9957\n",
            "Epoch 29: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.5767 - val_accuracy: 0.8650\n",
            "Epoch 30/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9986\n",
            "Epoch 30: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.6192 - val_accuracy: 0.8567\n",
            "Epoch 31/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9950\n",
            "Epoch 31: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.5987 - val_accuracy: 0.8617\n",
            "Epoch 32/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9964\n",
            "Epoch 32: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.5866 - val_accuracy: 0.8633\n",
            "Epoch 33/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9971\n",
            "Epoch 33: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.6059 - val_accuracy: 0.8567\n",
            "Epoch 34/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9971\n",
            "Epoch 34: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 0.6507 - val_accuracy: 0.8617\n",
            "Epoch 35/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9971\n",
            "Epoch 35: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.6395 - val_accuracy: 0.8567\n",
            "Epoch 36/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9971\n",
            "Epoch 36: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 0.6641 - val_accuracy: 0.8467\n",
            "Epoch 37/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9986\n",
            "Epoch 37: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.6770 - val_accuracy: 0.8483\n",
            "Epoch 38/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9979\n",
            "Epoch 38: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.6877 - val_accuracy: 0.8533\n",
            "Epoch 39/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993\n",
            "Epoch 39: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.7676 - val_accuracy: 0.8533\n",
            "Epoch 40/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9979\n",
            "Epoch 40: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.7260 - val_accuracy: 0.8600\n",
            "Epoch 41/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9964\n",
            "Epoch 41: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0061 - accuracy: 0.9964 - val_loss: 0.7448 - val_accuracy: 0.8567\n",
            "Epoch 42/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.8533\n",
            "Epoch 43/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9993\n",
            "Epoch 43: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.7844 - val_accuracy: 0.8550\n",
            "Epoch 44/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9993\n",
            "Epoch 44: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 80ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.8068 - val_accuracy: 0.8600\n",
            "Epoch 45/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8172 - val_accuracy: 0.8500\n",
            "Epoch 46/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 8.3170e-04 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 8.3170e-04 - accuracy: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.8617\n",
            "Epoch 47/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
            "Epoch 47: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 77ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.8438 - val_accuracy: 0.8467\n",
            "Epoch 48/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9993\n",
            "Epoch 48: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.8995 - val_accuracy: 0.8500\n",
            "Epoch 49/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 4.9081e-04 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 4.9081e-04 - accuracy: 1.0000 - val_loss: 0.9399 - val_accuracy: 0.8500\n",
            "Epoch 50/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9986\n",
            "Epoch 50: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 0.9298 - val_accuracy: 0.8500\n",
            "Epoch 51/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9993\n",
            "Epoch 51: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.9145 - val_accuracy: 0.8467\n",
            "Epoch 52/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9971\n",
            "Epoch 52: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 101ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.8678 - val_accuracy: 0.8450\n",
            "Epoch 53/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9986\n",
            "Epoch 53: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 0.8532 - val_accuracy: 0.8467\n",
            "Epoch 54/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 9.7139e-04 - accuracy: 0.9993\n",
            "Epoch 54: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 5s 117ms/step - loss: 9.7139e-04 - accuracy: 0.9993 - val_loss: 0.9376 - val_accuracy: 0.8517\n",
            "Epoch 55/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986\n",
            "Epoch 55: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.9338 - val_accuracy: 0.8500\n",
            "Epoch 56/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 6.4788e-04 - accuracy: 1.0000\n",
            "Epoch 56: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 6.4788e-04 - accuracy: 1.0000 - val_loss: 0.9346 - val_accuracy: 0.8450\n",
            "Epoch 57/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
            "Epoch 57: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.9331 - val_accuracy: 0.8450\n",
            "Epoch 58/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 2.6906e-04 - accuracy: 1.0000\n",
            "Epoch 58: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 6s 136ms/step - loss: 2.6906e-04 - accuracy: 1.0000 - val_loss: 0.9514 - val_accuracy: 0.8433\n",
            "Epoch 59/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 5.6343e-04 - accuracy: 1.0000\n",
            "Epoch 59: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 5.6343e-04 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.8417\n",
            "Epoch 60/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 6.1058e-04 - accuracy: 1.0000\n",
            "Epoch 60: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 100ms/step - loss: 6.1058e-04 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.8433\n",
            "Epoch 61/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 8.3610e-04 - accuracy: 1.0000\n",
            "Epoch 61: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 92ms/step - loss: 8.3610e-04 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.8417\n",
            "Epoch 62/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 8.5770e-04 - accuracy: 1.0000\n",
            "Epoch 62: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 8.5770e-04 - accuracy: 1.0000 - val_loss: 0.9878 - val_accuracy: 0.8367\n",
            "Epoch 63/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9986\n",
            "Epoch 63: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.0022 - accuracy: 0.9986 - val_loss: 1.0429 - val_accuracy: 0.8450\n",
            "Epoch 64/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 2.1482e-04 - accuracy: 1.0000\n",
            "Epoch 64: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 2.1482e-04 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.8367\n",
            "Epoch 65/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 5.4433e-04 - accuracy: 1.0000\n",
            "Epoch 65: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 5.4433e-04 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.8383\n",
            "Epoch 66/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 8.0301e-05 - accuracy: 1.0000\n",
            "Epoch 66: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 3s 80ms/step - loss: 8.0301e-05 - accuracy: 1.0000 - val_loss: 1.0609 - val_accuracy: 0.8483\n",
            "Epoch 67/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 1.0625e-04 - accuracy: 1.0000\n",
            "Epoch 67: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 1.0625e-04 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.8533\n",
            "Epoch 68/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 8.4922e-05 - accuracy: 1.0000\n",
            "Epoch 68: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 8.4922e-05 - accuracy: 1.0000 - val_loss: 1.1349 - val_accuracy: 0.8467\n",
            "Epoch 69/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 3.2743e-04 - accuracy: 1.0000\n",
            "Epoch 69: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 3.2743e-04 - accuracy: 1.0000 - val_loss: 1.1249 - val_accuracy: 0.8500\n",
            "Epoch 70/70\n",
            "44/44 [==============================] - ETA: 0s - loss: 3.5230e-04 - accuracy: 1.0000\n",
            "Epoch 70: val_accuracy did not improve from 0.86833\n",
            "44/44 [==============================] - 7s 155ms/step - loss: 3.5230e-04 - accuracy: 1.0000 - val_loss: 1.1407 - val_accuracy: 0.8483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "best_model = keras.models.load_model(\"best_model1.hdf5\")"
      ],
      "metadata": {
        "id": "dnXIUOeAALPk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ],
      "metadata": {
        "id": "G5r1a4CoAQoN",
        "outputId": "c68b3b13-958a-4cfa-8d68-1cdbe92ab048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 - 1s - loss: 0.4723 - accuracy: 0.8683 - 754ms/epoch - 40ms/step\n",
            "Model accuracy:  0.8683333396911621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "pw_1i4JmBE97"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))"
      ],
      "metadata": {
        "id": "Dd6yc-uq3d3P"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
        "#Normalizing\n",
        "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})"
      ],
      "metadata": {
        "id": "vVTWi_rdAXTB",
        "outputId": "6f16fcaf-dc1d-4e46-b7fb-dc6fb76d34a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa5cef74d50>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = ['Neutral','Negative','Positive']\n",
        "sequence = tokenizer.texts_to_sequences(['this experience has been the worst , want my money back'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "id": "9Afh_2QIAiT5",
        "outputId": "c36b72d8-a47f-43fc-ca9e-598c8ff29bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Negative'\n",
        "sequence = tokenizer.texts_to_sequences(['this data science article is the best ever'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "id": "L4zZWLczAoNt",
        "outputId": "295484a1-d218-43a8-db39-8eadaa397fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Neutral'"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Positive'\n",
        "sequence = tokenizer.texts_to_sequences(['i hate youtube ads, they are annoying'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "id": "HUgan-AwApx-",
        "outputId": "4f0f97ce-9844-4f6d-f7cf-90f8c4ed7f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Neutral'"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Negative'\n",
        "sequence = tokenizer.texts_to_sequences(['i really loved how the technician helped me with the issue that i had'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "id": "w8Mw-eHJArUS",
        "outputId": "52a2cb3c-16cd-489c-a493-9ccf030e10ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RdxhsM-QBPZp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}